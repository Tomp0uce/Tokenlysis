# Tokenlysis

Spécification du site web de scoring des cryptomonnaies
1. Spécifications fonctionnelles détaillées
1.1 Aperçu général du projet
Le projet consiste à développer un site web public permettant de générer et visualiser des scores dynamiques pour un large univers de cryptomonnaies (plus de 1000 actifs). Ces scores sont calculés à partir d’un grand nombre de paramètres hétérogènes (environ une centaine) couvrant divers aspects de chaque projet crypto : taille du marché, liquidité, activité communautaire, dynamique de prix, santé du protocole, etc. L’objectif principal est de fournir aux utilisateurs une évaluation globale de chaque cryptomonnaie, ainsi que des scores par catégorie thématique (p. ex. Communauté, Liquidité, Opportunité, Sécurité, Technologie, Tokenomics) afin de permettre une analyse plus fine.
En plus des 1000 premières cryptomonnaies (par exemple classées par capitalisation de marché), le site offrira une section dédiée aux 100 cryptomonnaies “tendances” hors top 1000, afin d’identifier les nouveaux projets émergents. Cette liste “Trending” sera déterminée automatiquement en fonction de l’intérêt récent porté à ces actifs (par exemple volumes d’échange, nombre de recherches/consultations, mentions sur les réseaux sociaux). Sur CoinMarketCap, les cryptos « trending » sont définies comme celles ayant le plus de visibilité sur le site sur 24h, reflétant l’engouement ou les mouvements du marché à court terme[1]. Nous appliquerons une logique similaire pour identifier ces tendances hors top 1000.
Chaque cryptomonnaie suivie disposera donc d’un score global agrégé ainsi que de scores par catégorie. L’utilisateur pourra consulter l’historique complet de ces scores dans le temps, afin de réaliser du backtesting (par exemple, évaluer comment les scores auraient pu anticiper l’évolution du prix, ou construire des stratégies basées sur les scores passés). Le site permettra également de personnaliser la pondération des critères de scoring selon des règles définies par l’utilisateur, afin que chacun puisse obtenir un score ajusté à sa propre méthodologie ou stratégie d’investissement.
1.2 Scores globaux et scores par catégorie
Les scores globaux fourniront une note synthétique (par exemple sur 100 ou en pourcentage) représentant la qualité ou le potentiel global d’une cryptomonnaie. Ce score global sera calculé à partir des scores de différentes catégories thématiques :
	Communauté : mesure l’engagement et la taille de la communauté du projet. Par exemple, nombre d’abonnés Twitter, taux d’interaction sur les réseaux sociaux, activité des forums/Telegram, etc. Une communauté large et active est souvent un indicateur de popularité et de soutien au projet[2]. En effet, la taille de la communauté (ex. nombre de followers Twitter) montre une corrélation avec la valorisation d’un projet crypto[3], il est donc pertinent de l’inclure dans le scoring.
	Liquidité : évalue la facilité à acheter/vendre l’actif. Paramètres clés : capitalisation de marché, volume d’échange 24h, nombre d’exchanges où le token est listé, liquidité sur les principaux DEX, spread achat/vente, etc. Un score de liquidité élevé signifie que l’actif est largement disponible et que le marché pour cet actif est profond (peu de slippage).
	Opportunité : reflète le momentum de marché et le potentiel de gain à court/moyen terme. On y intégrera des indicateurs techniques tels que le RSI (Relative Strength Index) sur différentes périodes, la volatilité récente, la performance par rapport à son plus haut/bas historique, ou des signaux de tendance. Par exemple, un RSI sur 14 jours est un oscillateur de momentum allant de 0 à 100 ; une valeur >70 indique un actif survendu, <30 un actif suracheté[4] – ces informations peuvent signaler des opportunités d’achat ou de vente. Le score Opportunité pourra ainsi monter si un actif semble survendu (potentiellement intéressant à acheter) ou présenter une dynamique positive.
	Sécurité : englobe la fiabilité et les risques techniques du projet. Critères possibles : audits de sécurité réalisés, absence de hacks connus, décentralisation du réseau (nombre de validateurs/noeuds), robustesse du code, durée de fonctionnement sans incident, et éventuellement conformité réglementaire. Un projet avec plusieurs audits réussis et aucun hack aura un meilleur score Sécurité. (NB : certaines de ces données peuvent être qualitatives ou difficiles à obtenir via API ; le score Sécurité initial pourra se focaliser sur des éléments quantifiables comme le temps écoulé depuis le lancement sans incident majeur, la distribution de hashrate ou de staking pour mesurer la décentralisation, etc., avec possibilité d’enrichir plus tard.)
	Technologie : évalue l’aspect technique et l’activité de développement. Paramètres : nombre de commits GitHub sur les dépôts du projet sur les X derniers mois, nombre de contributeurs actifs, fréquence des releases, qualité de la documentation technique, innovations apportées par le projet, etc. L’idée est de quantifier l’investissement des développeurs et l’évolution du code. Un rythme soutenu de commits et de contributions traduit un projet vivant et en amélioration constante. (On pourra utiliser l’API GitHub pour extraire le nombre de commits ou d’actions sur le dépôt principal, ou s’appuyer sur des statistiques agrégées fournies par des sites comme CoinGecko qui mesurent l’« activity » développeur.)
	Tokenomics : analyse l’économie du token. Ce score prend en compte la distribution de l’offre (par exemple concentration des tokens parmi les principales adresses), le market cap pleinement dilué, l’inflation ou la déflation du token (taux d’émission), les mécanismes de burn, le cas d’usage du token, le calendrier de déverrouillage des tokens bloqués (“vesting/unlock schedule”), etc. En somme, tout ce qui touche à la valeur intrinsèque du token et à son modèle économique (un supply bien réparti et une inflation maîtrisée conduisent à un meilleur score). Par exemple, la tokenomics est un facteur critique pour évaluer la valeur d’un actif et comprendre comment il génère et maintient sa valeur sur le long terme[5].
Chaque catégorie donnera un score partiel (probablement normalisé sur 100 également), et le score global sera une agrégation pondérée de ces scores catégoriels. Les catégories ont été choisies de manière à couvrir l’essentiel des due diligences qu’un investisseur pourrait réaliser. On notera que des agrégateurs comme CoinGecko avaient historiquement introduit des scores “developer”, “community” et “liquidity” pour les projets[6], reflétant l’importance de ces dimensions – notre approche s’inscrit dans le même esprit en l’étendant à d’autres axes (Sécurité, Tokenomics, Opportunité).
1.3 Paramètres et données pris en compte dans le scoring
Pour calculer ces scores, le système collectera quotidiennement une centaine de paramètres bruts pour chaque cryptomonnaie. Ces paramètres incluent notamment :
	Données de marché : prix, capitalisation boursière, volume d’échange sur 24h, rang de capitalisation, liquidité des order books, nombre d’exchanges listant l’actif, etc. (Sources probables : CoinGecko, CoinMarketCap).
	Indicateurs techniques : RSI sur 14 jours (et possiblement sur 7j/30j), volatilité (écart-type des retours sur 30j), tendance de prix (pentes sur 7j, 30j), etc., calculés à partir des historiques de prix. Certaines données techniques peuvent provenir directement de services (par ex. CoinMarketCap propose un indice de RSI global du marché crypto[7], mais ici nous calculerons le RSI par actif via nos propres scripts sur les données de prix).
	Statistiques de communauté : nombre d’abonnés Twitter officiels du projet, croissance du nombre d’abonnés sur 30 jours, nombre moyen de retweets/likes des posts récents (indiquant l’engagement), éventuellement nombre de membres Telegram/Discord, et possiblement des métriques de forum (Reddit abonnés, activité). Twitter sera la source principale compte tenu de son importance dans l’univers crypto (souvent appelé “Crypto Twitter”) et car la taille de l’audience Twitter d’un projet a un impact non négligeable sur sa visibilité et sa valorisation[3]. Par exemple, une étude a montré une relation claire entre le nombre de followers Twitter et la market cap d’un projet, au point de pouvoir estimer la valorisation théorique à partir des followers[3].
	Données de développement : nombre de commits GitHub sur le mois, nombre de contributeurs actifs, nombre d’étoiles et de watchers des dépôts GitHub, dernières mises à jour (un projet dont le dernier commit date de plus d’un an aura un score Technologie très faible). CoinGecko propose déjà de mesurer l’activité open-source et les statistiques de code sur 10k+ tokens[8][9], ce qui démontre la faisabilité de quantifier ce volet.
	Données DeFi (TVL) : pour les projets relevant de la finance décentralisée (DeFi), récupération du Total Value Locked (TVL) via l’API DeFiLlama notamment. Le TVL est défini comme la somme de la valeur des actifs bloqués dans les smart contracts du protocole (dépôts utilisateurs pour farming, lending, etc.)[10]. Une évolution positive de la TVL indique une adoption croissante du protocole et sera un facteur dans le score Opportunité (voire Liquidité pour les DEX).
	Données GitHub sécuritaires : par exemple, utilisation de l’API GitHub pour vérifier si le projet a un programme de bug bounty, ou tags de sécurité. De plus, on pourra intégrer le nombre de “forks” du code (un projet très forké peut être signe d’une base de code réutilisée et donc potentiellement auditée par plusieurs équipes, ou au contraire un fork multiple peut signaler des projets clones – à analyser prudemment).
	Autres : on envisagera des paramètres additionnels tels que : l’âge du projet (temps écoulé depuis le lancement du mainnet ou ICO), la présence sur les médias (nombre d’articles ou de recherches Google Trends), les notes externes (par ex. rating de sites comme TokenInsight ou Weiss Ratings), etc. Ces paramètres ne feront pas forcément partie de la première version, mais l’architecture doit permettre d’en ajouter facilement.
Tous ces paramètres seront collectés quotidiennement via des appels aux API de sources fiables : principalement CoinGecko et CoinMarketCap pour les données de marché, l’API Twitter pour les statistiques sociales, l’API GitHub pour l’activité de développement, l’API DeFiLlama pour le TVL DeFi, etc. Des sources complémentaires spécialisées pourront être ajoutées au besoin (par ex. LunarCrush pour des métriques sociales plus poussées, Glassnode pour des données on-chain, etc., si pertinents).
Le choix de rafraîchir les données une fois par jour (fréquence quotidienne) est motivé par le fait qu’on vise des scores dynamiques mais pas en temps réel intraday. Une mise à jour quotidienne représente un bon compromis entre réactivité du score et bruit évité (les fondamentaux ne changent pas d’heure en heure). De plus, plusieurs API tierces n’offrent que des données mises à jour quotidiennement ou avec un certain délai (par ex. les endpoints historiques de CoinGecko renvoient souvent des valeurs journalières).
L’horaire de collecte (par ex. chaque jour à 00:00 UTC ou à une heure creuse locale) sera fixé de sorte à avoir des points quotidiens cohérents pour l’historique.
1.4 Historique des scores et fonction de backtesting
Le système conservera l’historique complet de l’ensemble des scores calculés chaque jour, tant le score global de chaque crypto que ses scores par catégorie, et idéalement aussi les principaux paramètres bruts ayant conduit à ces scores (pour permettre des recalculs ou des analyses ultérieures).
Cette historique permettra aux utilisateurs de visualiser l’évolution d’un score dans le temps au travers de graphiques de tendance interactifs. Par exemple, un utilisateur pourra afficher la courbe du score global de Bitcoin sur les 12 derniers mois, ou comparer l’évolution du score “Communauté” de deux projets concurrents sur une période donnée. La présence de ces données historiques est cruciale pour le backtesting : un analyste pourrait, par exemple, tester une stratégie consistant à investir dans les cryptos dont le score Opportunité dépasse un certain seuil et observer, via les données passées, quelle aurait été la performance de cette stratégie.
Fonctionnellement, l’interface permettra : - De sélectionner une cryptomonnaie et d’afficher un graphique de l’une de ses scores (global ou par catégorie) sur une période réglable (par ex. 1 mois, 3 mois, 1 an, personnalisation via un sélecteur de dates). - De comparer sur un même graphique l’évolution de plusieurs cryptos. Par exemple, l’utilisateur coche 3 cryptos dans la liste puis choisit d’afficher la courbe de score global de ces 3 actifs sur 2024 afin de voir lequel avait les meilleurs scores à quels moments. - De visualiser également, en option, le cours de la cryptomonnaie en parallèle du score sur le graphique, pour voir les corrélations (par ex. si une hausse du score Prisé/Opportunité précède une hausse de prix, etc.). - D’accéder aux données chiffrées exactes (par ex. via un tableau téléchargeable ou une infobulle sur le graphique donnant la valeur du score à une date précise).
Pour permettre cela, la base de données conservera chaque jour pour chaque crypto : le score global, chaque score de catégorie, et idéalement un ensemble agrégé des métriques brutes (ou une référence vers les valeurs sources du jour). L’historique pourra potentiellement contenir des milliers de points par crypto sur plusieurs années, il faudra donc veiller à l’optimisation (indexation par dates, requêtes paginées). Toutefois, 1000 cryptos * 365 jours = 365k enregistrements par an pour un score global par jour, ce qui reste modéré pour une base de données relationnelle bien indexée. Si on stocke 7 scores (global + 6 catégories) par crypto par jour, on est à ~2,5 millions de valeurs par an, ce qui demeure gérable avec un SGBD classique (quelques millions de lignes).
1.5 Personnalisation des pondérations de score
Un point fort attendu du système est la personnalisation des règles de scoring. Chaque utilisateur connecté pourra définir ses propres pondérations pour les catégories (voire pour certains paramètres spécifiques) afin de recalculer un score global personnalisé selon ses préférences d’analyse.
Par exemple, un utilisateur A peut estimer que la Communauté est primordiale et pondérer fortement ce critère dans le score global, tandis qu’un utilisateur B mettra l’accent sur la Technologie et la Sécurité. L’interface proposera donc un écran (ou panneau) de réglage des pondérations : probablement des sliders ou des champs numériques permettant d’assigner un poids à chaque catégorie (% du total, la somme des poids devant faire 100%). Des préréglages pourront être offerts (ex : profil “Équilibré” par défaut, profil “DeFi” donnant plus de poids à la Liquidité et à la Sécurité, profil “Trader” mettant l’accent sur l’Opportunité, etc.).
Une fois les pondérations personnalisées, l’utilisateur pourra appliquer celles-ci et voir tous les scores recalculés dynamiquement en conséquence : - Le tableau/ranking des cryptos s’actualisera selon le nouveau score global calculé avec ces poids. - Les graphiques historiques pourront également être recalculés avec ces pondérations (ce qui implique de recalculer rétroactivement le score global personnalisé à partir des composantes historiques – d’où l’intérêt de stocker aussi les scores par catégorie ou suffisamment de données historiques pour le faire). - L’utilisateur pourra enregistrer ces pondérations dans son profil pour les réutiliser à chaque connexion, ainsi que potentiellement définir plusieurs profils de pondération et basculer de l’un à l’autre.
Techniquement, cette personnalisation signifie que le moteur de scoring doit supporter deux modes : 1. Mode par défaut : calcul des scores selon la pondération standard définie par l’équipe (pondérations “officielles” figées ou ajustées ponctuellement par l’administrateur, communes à tous les visiteurs non connectés). 2. Mode personnalisé : calcul à la volée en fonction des poids d’un utilisateur.
On peut envisager que les scores par catégorie et la plupart des agrégations soient pré-calculés quotidiennement et stockés. Ainsi, recalculer un score global personnalisé revient à faire une combinaison linéaire (une somme pondérée) des 6 scores de catégorie pré-enregistrés – opération triviale et très rapide côté front-end ou back-end. Par exemple : score_global_custom = w1*ScoreCommunauté + w2*ScoreLiquidité + ... + w6*ScoreTokenomics (avec w1..w6 les poids normalisés de l’utilisateur). Le recalcul de 1000 scores globaux customisés (pour reclasser les cryptos) ne prendrait que quelques millisecondes côté serveur, ce qui permet d’actualiser l’affichage presque instantanément après un changement de poids par l’utilisateur.
Il faudra veiller à l’ergonomie de cette fonctionnalité pour qu’elle soit compréhensible : par exemple afficher les poids en pourcentage, vérifier que la somme fait 100%, voire offrir la possibilité de “verrouiller” certains poids et d’équilibrer automatiquement les autres. Une option de retour au poids par défaut sera proposée.
1.6 Fonctionnalités de l’interface utilisateur
L’application web fournira une interface moderne et interactive incluant les fonctionnalités principales suivantes :
	Tableau de bord des scores : page principale affichant la liste des cryptomonnaies (au moins le top 1000 + section trending) sous forme de tableau. Ce tableau contiendra par ligne : le rang, le nom/symbole de la crypto, son prix actuel, et surtout son score global actuel ainsi que éventuellement une mini-indication de tendance (par ex. flèche verte/rouge selon l’évolution du score sur 7 jours). L’utilisateur pourra trier ce tableau par score global ou par n’importe quelle colonne.
	Filtres par type de crypto : possibilité de filtrer la liste sur des catégories de projets (au sens thématique). Par exemple, boutons ou cases à cocher pour filtrer uniquement les cryptos DeFi, ou celles liées à l’IA, au Gaming, aux Layer1, etc. Ces catégorisations seront pré-définies (on pourra utiliser les tags/categories de CoinGecko ou CMC pour chaque crypto). Ainsi un investisseur intéressé par les cryptos de jeux vidéo pourra filtrer “Gaming” et ne voir que celles-ci, triées par score.
	Filtres/tri par score : l’utilisateur pourra aussi filtrer par niveau de score (par ex. n’afficher que les projets ayant un score Sécurité > 80/100, ou un score Opportunité dans le top 10%). Il pourrait y avoir des curseurs de plage de score pour chaque catégorie. De plus, le tri du tableau pourra s’effectuer non seulement sur le score global, mais sur n’importe quel score de catégorie en cliquant sur l’en-tête de colonne correspondante (par ex. trier par score Technologie pour voir les projets techniquement les plus aboutis).
	Comparaison de cryptos : l’interface permettra de sélectionner manuellement plusieurs cryptomonnaies (via des cases à cocher dans la liste, ou en épinglant des lignes) afin de comparer leurs scores en détail. Une fois la sélection faite (par ex. 3 actifs), l’utilisateur pourra ouvrir un panneau de comparaison ou une page dédiée qui affichera côte-à-côte les scores de chaque catégorie pour ces actifs, peut-être sous forme de radar chart (diagramme en toile d’araignée) ou de barres comparatives. Il verra ainsi les forces et faiblesses relatives de chaque actif. Par exemple, comparer Bitcoin, Ethereum et un autre altcoin sur ces 6 catégories. Cette fonction aide à la décision en visualisant rapidement quel actif excelle dans quelle dimension.
	Graphiques de tendance et indicateurs visuels : pour chaque crypto, en plus des valeurs chiffrées, des mini-graphiques sparklines pourront être affichés directement dans le tableau pour montrer l’évolution du score global sur les 7 derniers jours par exemple, ou l’évolution du prix. Des codes couleur seront utilisés pour les scores (par ex. vert élevé, rouge faible, dégradé du rouge au vert selon le score). Les variations de score d’un jour à l’autre pourront être indiquées (ex: +2, -5 à côté du score, avec couleur et flèche correspondantes).
	Accès aux sources de données : transparence oblige, l’interface offrira pour chaque métrique affichée la possibilité de consulter sa source originale. Par exemple, à côté d’un chiffre de Market Cap ou de Followers Twitter, un petit icône “source” cliquable pourrait renvoyer à la page CoinMarketCap ou CoinGecko correspondante, ou au profil Twitter du projet. De même, un lien vers les données TVL sur DeFiLlama pourrait être fourni pour les projets DeFi. Cela permettra aux utilisateurs de vérifier les chiffres à la source et d’obtenir plus de détails. (Cette fonctionnalité sera à implémenter prudemment pour ne pas surcharger l’UI, peut-être via un pop-up "Données sources" listant les API ou sites utilisés.)
	Export des scores : l’utilisateur pourra exporter les données de scoring facilement, notamment dans un format tableur (CSV/Excel). Par exemple, sur la page de comparaison ou la page d’historique, un bouton “Exporter” permettra de télécharger les scores sélectionnés sur la période sélectionnée. Sur le tableau principal, un export complet des scores actuels de toutes les cryptos pourrait être proposé (avec éventuellement un warning sur la taille). L’export permettra aux utilisateurs avancés de faire leurs propres analyses offline.
	Recherche et Watchlist : une barre de recherche permettra de trouver une cryptomonnaie par son nom ou son symbole rapidement. De plus, les utilisateurs authentifiés auront la possibilité de créer une watchlist (liste personnalisée d’actifs favoris) pour accéder plus vite aux scores de ceux-ci. La watchlist pourrait apparaître en en-tête du tableau ou dans un onglet à part, avec des notifications d’évolution de scores éventuellement (future amélioration).
	Internationalisation : le site étant public, on peut prévoir plusieurs langues d’interface (français par défaut, anglais etc.), bien que dans un premier temps français suffira si l’audience visée est locale. La conception tiendra compte de la possibilité de traduire les labels statiques.
Toutes ces fonctionnalités devront être accessibles de manière fluide et réactive grâce à une interface optimisée. La section 3 détaillera les aspects UX/UI concrets de ces éléments.
2. Architecture technique
2.1 Vue d’ensemble de l’architecture
L’architecture du système suivra une approche modulaire en séparant les responsabilités entre le front-end, le back-end et le système de stockage (base de données), tout en intégrant un pipeline d’ETL (Extract-Transform-Load) pour la collecte des données externes. Voici les grands composants :
	Front-end (client) : une application web (HTML/CSS/JS) s’exécutant dans le navigateur de l’utilisateur, responsable de l’affichage de l’interface utilisateur, de l’interactivité (graphiques, filtres, etc.) et de la communication avec le back-end via des appels API. Ce front-end sera conçu comme une application single-page moderne (SPA) ou une application web classique dynamique, selon la stack choisie, mais dans tous les cas en mettant l’accent sur la réactivité (AJAX, etc.).
	Back-end (serveur d’API et scoring) : un serveur applicatif développé en Python, qui expose une API REST sécurisée permettant au front-end de récupérer les données (liste des cryptos, scores, historiques, etc.) et d’effectuer des actions (authentification, export…). Ce back-end contient également la logique métier : calcul des scores (selon les données collectées), agrégation, application des pondérations personnalisées, etc. Il intègre en outre les routines de collecte quotidienne des données via les API externes, faisant office d’ETL pour alimenter la base de données.
	Base de données : un système de gestion de base de données, hébergé localement (sur le NAS Synology) pour stocker toutes les données persistantes : données brutes collectées (optionnel si on stocke juste les scores calculés), scores calculés par catégorie et global, historiques journaliers, informations sur les cryptos (métadonnées, nom, symbole, catégorie sectorielle…), données utilisateur (comptes, préférences, pondérations personnalisées, watchlists), etc. La base de données devra supporter un volume important en lecture (consultation des scores) et des écritures quotidiennes (insertion des nouvelles données). On considérera une base relationnelle (SQL) robuste comme MariaDB ou PostgreSQL, ou éventuellement une base orientée séries temporelles pour optimiser le stockage des historiques, selon la faisabilité sur NAS.
	Environnement d’hébergement : l’ensemble sera déployé sur un NAS Synology, ce qui impose certaines contraintes mais aussi des outils spécifiques. Le NAS fera office de serveur, hébergeant le back-end Python (via Docker ou via le serveur web intégré Synology) et la base de données localement. Le Synology sera accessible en HTTP/HTTPS depuis internet pour servir l’interface aux utilisateurs.
En termes d’interaction, le flux typique est : un utilisateur accède au site via son navigateur -> le front-end (pages web) est servi -> le front-end appelle l’API du back-end (par ex. /api/scores?limit=1000) -> le back-end interroge la base de données et renvoie les données JSON -> le front-end affiche les scores. Certains calculs mineurs (comme appliquer localement des pondérations personnalisées) pourront éventuellement être faits côté front-end pour soulager le serveur, mais la source de vérité des données reste l’API.
Le moteur de collecte (ETL) du back-end fonctionnera en tâche de fond (probablement via une tâche planifiée quotidienne) pour interroger les API externes (CoinGecko, Twitter, etc.) et mettre à jour la base de données avec les nouvelles valeurs et scores calculés chaque jour (voir section 2.5).
L’architecture devra être sécurisée, scalable dans la mesure du possible sur le NAS, et optimisée pour délivrer rapidement les données au front-end (on pourra par exemple mettre en place un système de cache en mémoire sur le back-end pour certaines requêtes fréquentes, ou pré-calculer des agrégats).
2.2 Front-end (couche présentation)
Le front-end sera développé en mettant l’accent sur la performance et la compatibilité multi-plateformes (bureau, mobile). Deux approches sont possibles : - Framework front-end moderne (SPA) : Utilisation d’un framework JavaScript comme React, Vue.js ou Angular pour construire une application monopage. Cela permet une expérience utilisateur riche, avec mise à jour du DOM sans rechargement complet de page, transitions fluides, etc. Par exemple, React pourrait être choisi pour sa popularité et les nombreuses bibliothèques disponibles (notamment pour les graphiques). - Application web server-side rendue dynamiquement : Par exemple utiliser le framework web Python (Django, Flask) pour générer des pages HTML dynamiques côté serveur. Cette approche peut simplifier certaines choses (SEO, direct rendering), mais risque d’être moins interactive à moins d’injecter du JavaScript important.
Étant donné les exigences (graphiques interactifs, filtres dynamiques, mises à jour en temps réel lors de modifications de pondération), l’approche SPA semble appropriée. On pourrait également opter pour un compromis: utiliser Django pour servir l’application et gérer l’authentification, mais intégrer des composants Vue.js/React pour les parties vraiment interactives.
Technologies front-end : HTML5, CSS3 (probablement un framework CSS comme Bootstrap ou Tailwind pour accélérer le design responsive), JavaScript ES6+. Des librairies graphiques seront nécessaires pour tracer les courbes et graphiques : par exemple D3.js, Chart.js, ou des solutions haut niveau comme ECharts ou Highcharts. On peut aussi tirer parti de bibliothèques spécialisées crypto si elles existent, mais la plupart des besoins (courbes temporelles de scores, radars comparatifs) sont couverts par des libs génériques.
Le front-end communiquera avec le back-end via des appels HTTP RESTful (en GET pour récupérer des données, POST/PUT pour envoyer des modifications éventuelles). Le format des données échangées sera JSON.
Le front-end gérera également la stockage local de certains éléments non sensibles pour améliorer l’expérience : par ex, mémoriser dans le localStorage du navigateur les dernières cryptos consultées ou la pondération personnalisée choisie, afin de restaurer l’état plus rapidement.
Enfin, il sera responsive : testé et adapté pour différentes résolutions (mobile, tablette, desktop). Le design sera pensé “mobile-first” étant donné que beaucoup d’utilisateurs consultent ce genre d’outils sur smartphone.
2.3 Back-end (couche métier et API REST)
Le back-end sera réalisé en Python, comme spécifié, et se décompose en deux sous-ensembles principaux : l’API web (pour servir les données aux clients) et le moteur de scoring / ETL (pour collecter et traiter les données en arrière-plan).
Framework web : On peut s’appuyer sur un framework Python reconnu. Flask est une option légère et flexible, idéale pour créer rapidement des endpoints API REST. Django est plus lourd mais fournit d’emblée une ORM, un système d’admin et d’authentification, etc., ce qui peut accélérer le développement de la partie utilisateurs. FastAPI est également un candidat intéressant pour créer des API performantes en Python, avec en plus une documentation automatique intégrée. Étant donné la nature principalement “API” (peu de rendu de templates côté serveur si on part sur SPA), FastAPI pourrait être un très bon choix pour combiner performance et simplicité, tout en restant dans l’écosystème Python.
Les endpoints typiques de l’API pourraient être : - GET /api/cryptos : récupérer la liste des cryptos avec leurs scores actuels (éventuellement paginée). - GET /api/cryptos/{id} : détails d’une crypto particulière (scores, derniers paramètres, etc). - GET /api/cryptos/{id}/history?category=global&period=1y : historique des scores (global ou d’une catégorie) sur une période donnée. - GET /api/compare?ids=id1,id2,... : pour obtenir les scores de plusieurs cryptos à comparer. - POST /api/user/settings : pour enregistrer les préférences utilisateur (dont pondérations personnalisées). - POST /api/auth/login / POST /api/auth/register etc. : pour l’authentification (si non gérée via le framework). - GET /api/export?ids=...&format=csv&period=... : qui génère un fichier CSV à partir des données demandées.
Le back-end contiendra la logique de calcul des scores. Concrètement, lorsque les données brutes du jour sont collectées, le back-end calcule pour chaque crypto ses scores par catégorie selon des formules prédéfinies (voir section 4 sur le moteur de scoring) puis le score global standard. Ces valeurs sont stockées en base. À la demande d’un client, le back-end peut soit renvoyer les valeurs stockées (mode standard), soit recalculer un score global à la volée si un utilisateur applique ses pondérations personnalisées (alternativement, on peut renvoyer tous les scores par catégorie au front-end et laisser ce dernier faire le calcul, mais cela signifie transférer plus de données, donc le calcul côté serveur sur demande peut être préférable pour l’efficacité).
Sécurité de l’API : les endpoints sensibles (comme ceux modifiant les préférences, ou l’export, etc.) nécessiteront une authentification. On utilisera des tokens d’accès (par ex. JWT) ou des sessions sécurisées. Le site étant public en lecture, on permettra l’accès non authentifié en lecture seule aux endpoints de consultation des scores, mais certaines fonctionnalités avancées seront réservées aux comptes utilisateurs connectés (ex: sauvegarde de pondération, création de watchlist). On veillera aussi à protéger l’API contre les abus (limitation du nombre de requêtes par IP par minute pour éviter qu’un script externe vienne aspirer toutes les données sans permission, ce qui pourrait violer les conditions d’utilisation des API sources si on redistribue leurs données sans contrôle).
Le back-end devra également gérer la concurrence et la charge : possiblement plusieurs utilisateurs simultanés faisant des requêtes. Python étant naturellement monothread sur Flask, on pourra configurer un serveur WSGI (uWSGI ou Gunicorn) avec plusieurs workers pour gérer des requêtes concurrentes. On estime toutefois que la charge initiale sera modérée (site de niche pour analystes), mais l’architecture doit anticiper une montée en charge progressive.
2.4 Base de données et stockage des données
Étant donné l’environnement (NAS Synology) et les besoins, le choix de base de données s’oriente vers une solution SQL classique pour sa flexibilité. Synology offre nativement MariaDB 10 (un fork de MySQL) via son Centre de paquets. MariaDB est un candidat solide, supportant largement le volume envisagé. Sinon, on peut installer PostgreSQL via Docker ou package si disponible.
Les données principales à stocker : - Cryptomonnaies : table des actifs suivis (id interne, nom, symbole, éventuellement id externe CoinGecko/CMC pour référence, catégorie sectorielle, liens (site web, explorateur, etc.), drapeaux booléens (top1000 oui/non, trending oui/non par jour)). - Scores : table (ou tables) des scores journaliers. Par exemple une table scores_daily avec colonnes: crypto_id, date, score_global, score_communaute, score_liquidite, score_opportunite, score_securite, score_technologie, score_tokenomics, plus éventuellement la position rang du score global ce jour-là. Clé primaire composite (crypto_id, date). Index sur crypto_id et date séparément pour filtres. Cette table sera volumineuse (1000 * 365 ~ 365k lignes par an), mais c’est gérable. - Données brutes : on peut avoir des tables pour certaines données brutes importantes si on souhaite les historiser aussi. Ex: une table market_data (crypto_id, date, price, market_cap, volume, RSI, etc.). Toutefois, comme beaucoup de ces données servent juste à calculer le score, on peut choisir de ne pas toutes les stocker durablement pour économiser de la place, et ne garder que les scores. Une approche raisonnable : stocker quelques métriques clés pour transparence (ex: price, market_cap, volume, twitter_followers, tvl) dans l’historique, afin de pouvoir expliquer un score ou recalculer si besoin. - Utilisateurs : table des comptes utilisateurs (id, nom, email, hash de mot de passe, date d’inscription, etc.). - Paramètres utilisateurs : table séparée ou colonnes dans user pour les préférences (par ex un champ JSON ou plusieurs champs pour stocker les pondérations personnalisées de chaque catégorie, la watchlist de l’utilisateur, etc.). On peut aussi avoir une table user_weights liant user et des valeurs de poids pour chaque catégorie, mais étant donné qu’on a un nombre fixe de catégories, des colonnes dédiées dans la table user (ex: weight_communaute, weight_liquidite, ...) sont simples et efficaces. - Logs/monitoring : éventuellement tables de log des appels API, ou des erreurs, pour le suivi (bien qu’on puisse utiliser des fichiers log plutôt que la DB pour cela).
La base de données locale sur NAS signifie accès disque potentiellement plus lent que sur un gros serveur, mais acceptable pour nos usages. On activera peut-être l’écriture sur disque SSD cache du NAS si disponible pour accélérer. On configurera des sauvegardes régulières de la base (soit via l’outil de backup du NAS, soit un dump automatique).
Pour l’accès concurrent, l’ORM (si Django ou SQLAlchemy sous Flask) prendra en charge les connexions multiples. Il faudra configurer la base pour accepter les connexions depuis le back-end (si back-end en Docker, s’assurer que la base est accessible via socket TCP ou socket UNIX selon config – sur Synology, MariaDB écoute sur le port 3307 par défaut et il faut activer l’accès TCP/IP via l’interface Synology[11]).
Au niveau volumétrie, on doit aussi considérer les fichiers statiques : logos des cryptos, éventuelles icônes, etc. Ces éléments statiques peuvent être stockés sur le NAS (dossier web statique servi par Nginx par exemple). Les logos de 1000 cryptos peuvent être obtenus via les URLs de CoinGecko ou stockés localement pour performance. Une option économe est de récupérer les images via l’URL de CoinGecko à la volée (ils fournissent des URLs de petites icônes), ou d’en télécharger une fois un set de logos et les mettre dans un dossier statique. Le NAS Synology via Web Station/Nginx pourra servir ces fichiers efficacement.
2.5 Collecte des données externes (ETL)
Le back-end intègrera un module de collecte des données depuis les différentes API partenaires, qui s’exécutera quotidiennement de façon automatisée. Cette tâche peut être orchestrée de plusieurs façons : - En utilisant un scheduler interne (par ex. une tâche cron planifiée sur le NAS ou un scheduler Python comme APScheduler qui tourne avec l’appli). - En utilisant un outil dédié type Apache Airflow pour l’ETL, mais cela serait probablement excessif pour notre besoin et lourd à déployer sur NAS. - Plus simplement, via le planificateur intégré du NAS Synology : le DSM permet de créer des tâches planifiées (scripts shell ou commande) à exécuter à intervalles réguliers. On pourrait ainsi planifier un script Python quotidien qui lance la collecte.
La collecte consistera à appeler successivement les API : - CoinGecko API : pour récupérer les données de marché de l’ensemble des cryptos. CoinGecko propose un endpoint pour obtenir les infos d’un ensemble de coins en une seule requête (par exemple /coins/markets permettant de récupérer prix, market cap, volume, etc., pour 250 coins à la fois, qu’on peut appeler plusieurs fois pour couvrir 1000 coins). Ceci est important pour ne pas faire 1000 requêtes séparées. On respectera le rate limit de CoinGecko (30 appels/minute, 10k appels/mois sur l’API gratuite)[12][13]. Il faudra sans doute découper en 4 appels de 250 coins chacun, ce qui est faisable en une minute. On veillera à inclure dans la requête les champs nécessaires (CoinGecko peut renvoyer directement certains indicateurs comme le nombre d’abonnés Twitter, le score développeur et communauté s’ils étaient encore maintenus, etc., bien que ces derniers ne soient plus activement mis à jour par eux[14]). Si des données ne sont pas dispos sur CoinGecko, on pourra les obtenir via CoinMarketCap API en complément. - CoinMarketCap API : fournit également des données de marché et d’autres endpoints (trending, etc.). Cependant, son API gratuite est plus limitée (10 000 appels/mois également, et 333 appels/jour) avec un retour limité à 1 crypto par appel sur certains endpoints[15]. On privilégiera donc CoinGecko pour l’essentiel des données gratuites, et éventuellement CMC pour des compléments (par ex, CMC Trending endpoint pour obtenir la liste des trending daily). On notera que l’endpoint Trending de CMC fournit directement les cryptos populaires du jour avec quelques stats[1], utile pour notre catégorie trending hors top1000. - Twitter API : l’API Twitter v2 nécessite désormais un abonnement payant pour accéder à des données comme le nombre de followers d’un compte de manière automatisée. Nous aurons peut-être besoin de collecter quotidiennement le nombre d’abonnés du compte officiel de chaque projet. Pour 1000 projets, cela représente 1000 appels à l’API Twitter par jour, ce qui n’est pas possible avec un compte gratuit (limité à 1500 tweets/mois et pas d’endpoints utilisateurs dans le tiers gratuit). Alternatives : - Utiliser une API tierce ou un service comme LunarCrush qui fournit des métriques sociales agrégées (mais payant au-delà d’un point). - Scraping : récupérer la page publique du profil Twitter et parser le nombre d’abonnés. C’est risqué car contre les ToS et facilement bloqué. - Utiliser les données CoinGecko : CoinGecko, dans ses données de coins, fournit le nombre d’abonnés Twitter d’un projet (et Reddit subscribers, etc.). Si cela est toujours mis à jour, ce serait le plus simple. Sinon, on peut réduire la fréquence de collecte de ce paramètre (par ex hebdomadaire) pour rester dans les limites, ou choisir un échantillon (on peut imaginer que les 1000 principaux projets ont tous beaucoup de followers donc c’est important à jour, mais pour trending hors top1000 on peut se limiter).
Dans un premier temps, on tentera d’utiliser CoinGecko pour les métriques communautaires : leur API retourne community_data avec le nombre de Twitter followers, Reddit subs, etc., bien que ces chiffres ne soient pas toujours à jour en temps réel. Il faudra tester.
	GitHub API : pour les données de développement (commits, etc.). Ici aussi, 1000 requêtes distinctes (une par projet) posent un souci de rate limit (GitHub autorise 60 requêtes/h non authentifié, 5000/h authentifié par token). On devra utiliser une token d’auth GitHub (gratuit) pour bénéficier des 5000/h. On pourra de plus regrouper certaines requêtes si on connaît l’organisation GitHub du projet. Par exemple, on peut appeler l’API GraphQL de GitHub pour récupérer plusieurs repos en une seule requête complexe. Simplicité : on peut stocker pour chaque crypto l’URL du repo principal, et chaque jour appeler l’endpoint “commits” de l’API REST pour ce repo (ex: /repos/{owner}/{repo}/stats/commit_activity pour obtenir les commits par semaine). 1000 repos -> 1000 appels, on devra étaler sur plusieurs heures potentiellement pour rester dans 5000/h. On peut aussi ne pas collecter tous les jours chaque projet, mais lisser : par ex, vérifier l’activité de 1/7ème des projets chaque jour, car l’activité dev n’évolue pas drastiquement en 24h pour la plupart. Ainsi chaque projet serait mis à jour hebdomadairement. Cependant, pour simplicité, on peut d’abord s’appuyer sur CoinGecko qui fournit un champ developer_data (nombre de commits 4 weeks, etc.) pour éviter l’implémentation directe.
	DeFiLlama API : on l’utilisera pour récupérer la TVL des protocoles DeFi. DeFiLlama propose un endpoint pour la TVL de chaque protocole ainsi qu’un historique. On peut appeler l’endpoint “liste de tous les protocoles avec leur TVL”[16], ce qui renvoie un tableau de TVL par protocole. On pourra alors faire la correspondance avec nos cryptos (via le nom ou un identifiant commun). Cette opération étant relativement légère (quelques centaines de protocoles DeFi), on peut le faire quotidiennement. La TVL est un indicateur mis à jour très régulièrement (toutes les heures sur DefiLlama[17]), mais une capture journalière suffit pour notre usage.
	Autres API : par exemple si on veut détecter les trending hors top1000, on peut utiliser l’API de LunarCrush (qui fournit un “AltRank” des cryptos en fonction de l’activité sociale) ou simplement se baser sur les variations de volume/prix. On pourra créer notre propre métrique “trending” basée sur un score combinant augmentation de volume + hausse soudaine de mentions sur Twitter (si on a l’info) + visites (peut-être via CoinGecko qui traque les pages vues). CoinMarketCap propose aussi un endpoint pour trending comme vu plus haut. En fonction de l’accessibilité de ces données, on choisira l’approche.
Chaque API externe a ses contraintes de taux qu’il faudra respecter scrupuleusement pour éviter les bans temporaires ou des erreurs. On envisagera la mise en cache de certaines réponses si possible. Par exemple, CoinGecko limitant à ~30 req/min[12], on fera des pauses entre les appels ou regroupera les données. Pour Twitter/GitHub les stratégies ont été évoquées. En dernier recours, si certaines données sont trop coûteuses à collecter chaque jour, on peut décider de les mettre à jour moins fréquemment et d’interpoler (ex: MAJ hebdo du nombre de followers Twitter, avec interpolation linéaire sur la semaine pour les scores quotidiens – mais ceci sera documenté si fait, et pas idéal).
Le module ETL effectuera après la collecte une phase de transformation/calcul : normaliser les données brutes et calculer les scores (via le moteur de scoring). Par exemple convertir le nombre d’abonnés Twitter en un score sur 100 (en comparant aux autres projets), etc. Ces calculs sont détaillés en section 4.
Enfin, il stockera les résultats en base. Si la collecte du jour échoue partiellement (ex: API Twitter indisponible ce jour-là), le système devra quand même stocker ce qu’il a pu calculer et éventuellement réutiliser la dernière valeur connue pour tel paramètre manquant, ou marquer le score comme non disponible ce jour (mais on préfère éviter les trous dans l’historique). Une surveillance (monitoring) enverra une alerte en cas d’échec de la collecte (voir section 8).
2.6 Gestion des API keys et configuration
Les appels aux API tierces nécessitent de garder en sécurité certaines clés d’API (API key CoinMarketCap, clé OAuth Twitter, token GitHub, etc.). Sur le NAS Synology, nous devrons stocker ces clés dans un endroit non accessible publiquement : - Soit dans des variables d’environnement du processus Python (Synology permet de configurer des variables d’env dans Web Station ou on peut utiliser un fichier .env lu par l’application, qui ne sera pas exposé). - Soit dans un fichier de configuration sur le NAS, protégé en lecture (permissions restreintes).
En tout état de cause, ces clés ne doivent pas se retrouver dans le dépôt de code ou livrables accessibles. Une attention particulière sera portée à la configuration globale : un fichier de config (format .ini, .yaml ou .py) contiendra les constantes comme les URLs d’API, les clés, les paramètres de scoring par défaut, etc. Il y aura une distinction entre config de développement et config de production (ex: utiliser éventuellement des clés différentes ou modes simulés en dev).
En ce qui concerne l’infrastructure logicielle sur le NAS, deux choix se présentent : - Installer directement les services sur DSM : Installer le package Python du Synology (ce qui fournit Python3 et pip), installer MariaDB via le Centre de paquets, et utiliser Web Station (le serveur web de Synology) configuré avec Python/uWSGI pour exécuter l’application Flask/FastAPI. Synology DSM 7 supporte nativement les applis Python via uWSGI, nécessitant de créer un profil de script Python dans Web Station et de pointer vers le WSGI app[18][19]. Cette méthode permet de déployer sans conteneur. - Utiliser Docker : Si le NAS supporte Docker (ce qui est probable sur un modèle récent x64 mais pas sur tous, attention aux NAS ARM bas de gamme sans Docker), on peut conteneuriser l’application Python et la base de données. Par exemple, un conteneur Docker pour l’API Python (basé sur une image Python 3.x, exposant le port de l’API) et un conteneur pour PostgreSQL ou MariaDB. Avantages : isolation, facilité de maintenance (on peut builder l’image en CI/CD et la déployer), et moindre dépendance vis-à-vis des spécificités Synology. - Hybride : garder la base de données via le package Synology (MariaDB local) pour profiter de l’UI de gestion fournie (phpMyAdmin peut être installé sur Synology pour MariaDB), et conteneuriser uniquement l’application Python.
Le choix dépendra des contraintes du modèle de NAS. Si Docker est disponible et que l’équipe est à l’aise avec, c’est souvent plus propre. Sinon, l’option Web Station est viable ; on suivra des guides existants pour déployer Flask sur Synology DSM7[20][21]. Dans ce dernier cas, on configurera un Virtual Host via Web Station : sélection du backend Nginx, profil Python/WSGI vers notre app, port 443 avec certificat SSL (Synology gère Let’s Encrypt facilement).
3. Spécifications d’interface (UX/UI)
3.1 Principes généraux d’UX/UI
L’interface utilisateur sera conçue pour être moderne, claire et intuitive. Voici les principes directeurs : - Simplicité de navigation : L’utilisateur doit pouvoir d’un coup d’œil obtenir l’information principale (les scores des cryptos) et filtrer/chercher facilement. Le design évitera les écrans trop chargés en données brutes : on privilégiera les indicateurs synthétiques (scores, icônes) avec possibilité de détailler à la demande. - Responsive design : L’UI s’adaptera aux écrans de différentes tailles. Sur mobile, l’affichage du tableau pourrait être simplifié (scroll horizontal pour voir toutes les colonnes, ou possibilité de pivoter certaines infos en cartes). Sur desktop, on exploitera la largeur pour montrer plus de colonnes (par ex. tous les scores de catégories en colonnes additionnelles). - Performances et fluidité : L’utilisateur ne doit pas ressentir de latence importante lors de l’utilisation des filtres ou de la navigation. On utilisera des techniques de chargement asynchrone et de caching côté client pour que, par exemple, le fait d’appliquer un filtre n’entraîne pas un rechargement complet de la page mais juste le rafraîchissement du tableau concerné. - Cohérence visuelle : Une charte graphique harmonisée (couleurs cohérentes, typographie lisible, usage raisonné de symboles). Les scores pourraient être accompagnés d’un code couleur (rouge à vert) facilement compréhensible, mais il faudra aussi afficher la valeur numérique pour être précis. On veillera à l’accessibilité en choisissant des contrastes suffisants et en rendant les éléments navigables au clavier et lisibles par lecteurs d’écran autant que possible (WCAG standards). - Interactivité : Des éléments comme les graphiques seront interactifs (hover pour voir les valeurs exactes, légende cliquable pour afficher/masquer une série, etc.). Les transitions (par ex. afficher un panneau de comparaison) seront animées légèrement pour un rendu professionnel. Cependant, on évitera les gadgets superflus qui pourraient alourdir le site.
3.2 Structure de navigation et vues principales
On envisage la structure suivante pour l’application web : - Page d’accueil / Tableau de bord : c’est la page principale listant les cryptos avec scores. Elle servira de point de départ. Si l’utilisateur est connecté, elle peut afficher en plus sa watchlist en haut. - Page Trending : une section ou page montrant spécifiquement les 100 cryptos tendances hors top1000. Peut-être qu’on intégrera cela directement au tableau principal (par exemple un onglet “Trending” séparé du “Top 1000”). On pourrait avoir un menu ou des onglets pour naviguer entre Top 1000 et Tendances. Dans la section Trending, on listera ces projets avec les mêmes colonnes de scores, ou potentiellement un jeu de colonnes légèrement différent (par ex. inclure une colonne “rang trending” ou cause du trending). - Page détail d’une cryptomonnaie (en option) : si l’utilisateur clique sur le nom d’une crypto, on peut avoir une page dédiée avec davantage d’infos : un profil de la crypto (description, logo, lien site officiel), tous les scores en détail, un graphique multi-courbes montrant l’historique du score global vs prix, et possiblement des sous-graphiques pour chaque catégorie, ainsi que la liste des paramètres bruts du dernier jour (ex: “Market Cap = $X, Volume = $Y, Followers Twitter = Zk, Commits 30j = N, …”). C’est un niveau de détail qui intéressera les analystes plus pointus. Cette page détail ne faisait pas explicitement partie de la demande initiale, mais elle découle naturellement de l’envie d’expliquer un score. Nous l’inclurons dans la spécification pour complétude. - Page comparaison : affichant le comparatif de plusieurs cryptos sélectionnées. Ce pourrait être une page à part entière avec une URL du type /compare?ids=BTC,ETH,XRP ou un composant modale apparaissant sur la page principale. Une page dédiée offre plus d’espace pour afficher par exemple un graphique comparant les scores, un tableau comparatif chiffré, et éventuellement un radar chart. On opte pour une page dédiée accessible via un bouton “Comparer” une fois les cryptos cochées. - Pages utilisateur : Connexion/Inscription, Profil (permettant de modifier ses infos, et paramétrer ses pondérations, etc.). Ces pages seront classiques : un formulaire de login, un formulaire de création de compte, et une page profil avec les paramètres ajustables. - Page Méthodologie / A propos : utile pour expliquer comment les scores sont calculés, présenter l’équipe, les disclaimers (non-conseil financier). On la placera dans un menu d’information.
Le site aura une barre de navigation en haut (sur desktop) ou un menu hamburger (sur mobile) permettant d’accéder à : Accueil, Trending, (éventuellement “Mes Favoris” si connecté), Méthodologie, Profil (si connecté) ou Connexion.
3.3 Tableau de bord des scores (vue principale)
Cette vue contiendra : - En haut, un ensemble de filtres et outils : - Un champ Recherche (auto-complétion sur nom/symbole). - Les filtres de catégories de cryptos (sous forme de liste déroulante multi-sélection ou de boutons tags cliquables, par ex. “DeFi”, “NFT”, “Gaming”, etc.). Si l’utilisateur choisit un filtre, le tableau se met à jour pour n’afficher que les entrées correspondantes. - Des filtres par score/catégorie (par ex. des sliders ou champs min/max pour filtrer le score global ou un score catégorie). On peut recouvrir ces filtres dans une section “Filtres avancés” escamotable pour ne pas surcharger l’écran par défaut. - Un bouton Export (si on souhaite exporter la liste entière ou filtrée). - Un indicateur de dernière mise à jour (par ex. “Données mises à jour le JJ/MM/AAAA à HH:MM” pour informer l’utilisateur). - Le tableau lui-même, sous forme d’éléments tabulaires ou de cartes selon l’écran : - Colonnes probables : Rang (#), Nom (avec symbole, peut-être logo), Prix actuel, Variation 24h du prix (pour contexte, si on décide de l’inclure), Score global (mis en avant visuellement), puis éventuellement Score Communauté, Liquidité, Opportunité, Sécurité, Technologie, Tokenomics. Afficher les 6 scores catégoriels en colonnes peut sur desktop passer (total ~10 colonnes avec celles citées). Sur mobile, on ne pourra pas tout montrer : on privilégiera Score global et peut-être un moyen d’afficher les autres sur appui (ex: ligner cliquable qui déroule les détails de scores catégories). - Chaque cellule de score pourra contenir la valeur sur 100, et peut-être un petit symbole de tendance (ex: un triangle vert si en hausse vs hier, rouge si en baisse, stable sinon). - En cliquant sur la cellule d’un score catégorie, on pourrait ouvrir un mini-popup explicatif de la note (par ex: “Score Communauté 75 – Basé sur 120k followers Twitter et forte croissance ce mois-ci”). - Le tableau aura un tri activable en cliquant sur les en-têtes de colonne. Par défaut, la page d’accueil sera triée par rang (market cap) ou par score global (à définir). L’utilisateur peut cliquer “Score global” pour trier du plus haut au plus bas, etc. Une flèche de tri indique l’ordre. - Une pagination ou défilement infini : afficher top 100 par page par exemple, pour ne pas charger les 1000 d’un coup (bien que 1000 lignes ce n’est pas énorme en HTML, mais sur mobile c’est trop). On pourra charger 100 par 100. - Interaction sélection multiple : chaque ligne du tableau aura une case à cocher ou un bouton “comparer” pour ajouter la crypto à la sélection courante. Une fois au moins 2 cryptos sélectionnées, un bouton/flottant “Comparer X éléments” apparaît quelque part, incitant à passer à la vue comparatif. L’utilisateur peut aussi en cochant 1 crypto puis cliquant sur elle accéder direct à sa page détail (il faudra dissocier clic sur le nom -> page détail, vs case à cocher -> sélection). - Survol / tooltips : passer la souris (ou tap sur mobile) sur un score pourrait afficher un tooltip avec la décomposition ou la définition du score. Ex: survoler “Score Sécurité: 80” affiche “Audits OK, Pas de hack en 3 ans, Réseau décentralisé (1200 validateurs)”.
Exemple d’agencement sur desktop : à gauche, éventuellement une colonne fixe avec la liste de filtres (catégories, etc.) si on veut un panneau latéral. En haut, la barre de recherche. Puis le tableau occupe le reste. Sur mobile : la recherche en haut, un bouton “Filtres” qui ouvre un panneau latéral coulissant pour les options de filtrage.
Le design sera épuré : fond clair ou sombre selon le thème choisi (on pourrait implémenter un mode sombre vu la cible tech, comme coinmarketcap le propose). Typographie professionnelle (e.g. Roboto, Open Sans). Les scores pourraient être affichés dans une police légèrement plus large ou en gras pour bien ressortir.
3.4 Visualisation des tendances et graphiques
Pour la partie historique des scores, plusieurs graphiques seront utilisés : - Un graphique principal de type courbe (line chart) pour les scores dans le temps. L’utilisateur pourra choisir d’afficher soit le score global, soit une catégorie particulière, et éventuellement superposer cette courbe avec le prix de la crypto. Par exemple, sur la page de détail d’une crypto, on pourrait avoir le graphique du score global sur 1 an en bleu et le prix en pointillés gris sur l’autre axe. Les axes seront clairement étiquetés. En bougeant la souris, une infobulle affiche la date exacte et les valeurs de score et prix ce jour. - Des radar charts (diagrammes polygonaux) pour la comparaison de plusieurs cryptos sur les 6 catégories. Par exemple, si on compare Bitcoin vs Ethereum, on dessine un radar à 6 axes (Communauté, Liquidité, etc.) avec deux polygones l’un pour BTC l’autre pour ETH. Cela donne une visualisation immédiate de qui est meilleur sur quel axe. Ce type de graphique est intuitif pour comparer des profils. - Des bar charts ou colonnes pour des comparaisons ponctuelles : par exemple, on pourrait représenter sous forme de barres le score global de 5 cryptos sélectionnées côte à côte. - Des sparkline mini charts dans le tableau principal : une petite image 100x30px montrant l’évolution du score global sur 7 jours pour chaque ligne, ce qui aide à repérer visuellement les tendances (ces mini-graphs peuvent être intégrés en SVG ou canvas). - Couleurs : chaque catégorie pourrait avoir une couleur associée pour les graphes (ex: Communauté en orange, Liquidité en bleu, etc.), de sorte que sur un radar chart ou légende de courbe, on identifie la catégorie. Le score global pouvant être en couleur neutre (blanc) ou or.
L’interface graphique proposera des contrôles de période : boutons 1M, 3M, 1A, Max, ou un sélecteur de dates pour préciser l’intervalle. Cela enverra une requête pour les données correspondantes et redessinera le graphe.
Pour assurer la réactivité, on pourrait pré-charger certaines séries (par ex. le back-end peut envoyer par défaut l’historique 30j dans la réponse initiale de détail, et ne charger le reste que sur demande de l’utilisateur).
3.5 Interface de personnalisation des pondérations
Un élément d’UI sera dédié à la personnalisation des scores : - Accessible via la page Profil de l’utilisateur (ou un bouton “Personnaliser les scores” directement sur l’écran principal si connecté). - Il s’agira d’un formulaire de sliders : 6 curseurs, chacun étiqueté par la catégorie, allant de 0 à 100%. On peut l’afficher sous forme d’une barre segmentée de 100% au total. En déplaçant un curseur, soit on ajuste automatiquement les autres (pas trivial), soit on laisse la somme dépasser 100 et on affiche un avertissement. Mieux vaut peut-être une approche ou l’utilisateur renseigne des poids relatifs (pas forcément normalisés) et on normalise en interne. On pourrait permettre d’entrer un nombre pour chaque poids, ou de répartir 100 points entre les 6 catégories. - L’UI montrera peut-être en temps réel l’effet sur un exemple (ex: une prévisualisation du classement top10 selon les nouveaux poids). - Un bouton “Appliquer” recalculera les scores globaux affichés selon les pondérations choisies. Techniquement, le front-end pourrait juste envoyer les poids au serveur puis recevoir le nouveau classement, ou bien recalculer côté client si toutes les données par catégorie sont disponibles. Dans un premier temps, plus simple est d’appeler un endpoint du style /api/cryptos?weights=comm:2,liqu:1.5,... qui renvoie la liste triée. - Si l’utilisateur est content de ses réglages, il peut cliquer “Enregistrer mes préférences”, ce qui persistera ces poids dans son profil (pour qu’ils soient repris à la prochaine visite). - Un bouton “Réinitialiser par défaut” remettra les pondérations officielles.
Cette interface doit être intuitive car c’est une fonctionnalie avancée. On peut ajouter un petit i d’information à côté de chaque catégorie expliquant brièvement ce qu’implique augmenter ou diminuer son poids.
3.6 Expérience utilisateur sur mobile
Sur mobile, compte tenu de l’espace réduit, certaines adaptations seront faites : - Le tableau principal pourrait être transformé en une liste de cartes ou de lignes condensées. Par ex: chaque crypto affichée sur deux lignes : ligne1 avec rang, nom, prix, score global; ligne2 en plus petit avec les 6 scores de catégorie listés (ou un mini-bullet chart). Ou bien utiliser un carrousel horizontal dans la carte pour faire défiler les sous-scores. On veillera à ce que l’information principale (score global) soit visible sans scroller horizontalement. - Les graphiques interactifs (courbes) seront affichables en plein écran mobile au besoin, avec la possibilité de pinch-zoomer éventuellement. On utilisera des librairies qui gèrent le touch. - Le menu sera burger, et les filtres probablement dans un panneau coulissant comme mentionné.
Globalement, l’UI mobile sera simplifiée mais devra conserver les fonctionnalités (filtrer, comparer peut-être en ouvrant une vue dédiée). Il est envisageable que la comparaison de multiples cryptos soit moins pratique sur mobile, mais on peut par exemple présenter le radar chart occupant tout l’écran, et permettre de sélectionner/désélectionner les cryptos comparées via un mini-menu.
3.7 Exemples visuels (Wireframes)
(Note: dans la spécification écrite, on peut inclure quelques wireframes ou mockups pour illustrer, mais comme ce format texte ne les rend pas, nous décrivons ici textuellement.)
	Wireframe Accueil (Desktop) : En-tête avec logo du site et menu (Accueil, Trending, Méthodologie, Profil/Connexion). En dessous, barre de filtres (Recherche + filtres catégories + bouton filtres avancés + bouton export). Puis tableau : colonnes #, Nom, Prix, Score Global (avec une étoile ou medaille icone à côté du chiffre pour le rendre notable), Score Com, Score Liq, Score Opp, Score Sécu, Score Tech, Score Token. En bas pagination.
	Wireframe Page Détail : Titre avec le nom + symbole + logo de la crypto, un bouton “Ajouter à watchlist” si connecté. Ensuite une section avec les scores actuels (peut-être sous forme de jauges ou d’un radar chart pour la distribution). Puis un onglet “Historique” avec la courbe du score global vs prix. En-dessous, un tableau des paramètres du jour ou quelques faits saillants (ex: “Followers Twitter : 120k (+5% sur 7j)”, “Commits GitHub 30j : 15” etc.). Et un lien “Voir sur CoinGecko / CMC / Twitter”.
	Wireframe Comparaison : Titre “Comparer 3 cryptomonnaies : [BTC] [ETH] [ADA]” avec possibilité d’en retirer une. Ensuite deux onglets : “Radar” et “Tableau”. L’onglet Radar affiche le radar chart commun. L’onglet Tableau affiche un tableau comparatif avec en lignes les catégories et en colonnes les cryptos, avec leurs scores numériquement. En dessous, éventuellement un bouton “Exporter comparatif en CSV”.
3.8 Identité visuelle et branding
Le site étant public, lui donner une identité visuelle propre est utile. On choisira un nom de projet (par ex. “CryptoScore360” ou autre) et on créera un logo simple. La charte couleur pourrait par exemple associer une couleur à chaque catégorie de score pour rappeler ces thèmes : - Communauté : orange (couleur énergique) - Liquidité : bleu (finance) - Opportunité : vert (gain/optimisme) - Sécurité : gris ou noir (sécurité/robustesse) - Technologie : violet (innovation technique) - Tokenomics : turquoise (argent/économie) Le score global pourrait être en doré ou en blanc.
Ces couleurs seront utilisées pour les indicateurs, barres de score, etc., mais le reste de l’UI restera sobre (fond clair neutre ou mode sombre).
Les polices d’écriture seront choisies pour la lisibilité des chiffres en particulier (une police monospace pour afficher les valeurs pourrait même être envisagée dans le tableau pour aligner les chiffres, mais ce n’est pas obligatoire).
3.9 Accessibilité et aide utilisateur
On intégrera des info-bulles explicatives sur les termes techniques (par ex. survoler “RSI” affiche “Relative Strength Index – indicateur technique de momentum” pour les non-initiés). Une section “Méthodologie” (page dédiée) décrira en français clair comment les scores sont calculés, à quelles sources de données on fait appel, et les limites éventuelles.
Un soin sera apporté à l’accessibilité : chaque icône aura une alternative textuelle (attribut alt), les couleurs ne seront pas le seul vecteur d’information (ex: ajouter un signe +/– devant un chiffre de variation et pas juste la couleur), et la navigation clavier sera testée.
4. Détails sur la pondération et le moteur de scoring
Le moteur de scoring est le cœur de la logique métier : c’est lui qui transforme les multiples paramètres collectés en un ensemble de scores normalisés (0-100) sur chaque catégorie, puis en un score global.
4.1 Normalisation des paramètres
Étant donné la diversité des paramètres (certains sont des nombres bruts pouvant aller de 0 à des milliards, d’autres sont des pourcentages, etc.), il est nécessaire de normaliser ou standardiser chaque métrique pour pouvoir les combiner de manière cohérente.
Pour chaque paramètre, la spécification définira une méthode de transformation vers une échelle commune, typiquement 0 à 100 (100 étant le meilleur). Plusieurs méthodes possibles : - Min-Max scaling : sur une fenêtre glissante ou sur l’ensemble de l’univers courant. Par ex, on regarde les market caps de toutes les cryptos suivies, on considère le max (Bitcoin ~ grand) comme 100 pour la sous-métrique capitalisation, et le plus bas comme 0. Cette méthode est simple mais peut être distordue par des extrêmes (surtout hors top1000 il peut y avoir des valeurs aberrantes). - Scoring par paliers : définir des seuils absolus. Par ex, pour le nombre d’abonnés Twitter : 0 follower = 0, 1 million = 100, et on interpole (ou on plafonne à 100 au-delà d’un million). De même, RSI : on pourrait transformer un RSI de 70 en un score opportunité plus faible (car surachat), etc., donc la transformation n’est pas monotone simple (voir plus bas). - Classement relatif : convertir le rang d’une crypto sur un paramètre en un score. Par exemple, si on classe par nombre de commits et qu’une crypto est top1 sur cet axe, on lui donne 100 en Tech (ou proche), etc. Ce n’est pas très granulaire toutefois.
Une combinaison de ces approches sera utilisée selon les données : - Pour des métriques comme la capitalisation ou le volume qui varient sur des ordres de grandeur énormes, un scaling logarithmique est pertinent. On peut définir Score_Liquidité_partiel_cap = 100 * log10(cap du projet) / log10(cap max) par exemple. Ainsi, un projet avec cap 10^9 vs un de 10^12 aura un score de 75 si l’autre est 100 (car log10(1e9)=9 vs log10(1e12)=12, 9/12 = 0.75). - Pour le RSI qui est déjà borné 0-100 : on peut définir un sous-score Opportunité basé sur RSI qui donne 100 au RSI=30 (survente maximale, opportunité d’achat), qui décroit ensuite et donne 0 à RSI=70 (surachat maximal, donc opportunité nulle ou opportunité de vente dans l’autre sens). On peut même faire une fonction triangulaire centrée sur 50 ou calibrée différemment. Étant donné que RSI > 70 est suracheté, on peut dire : Score_opportunite_RSI = max(0, (70 - RSI) * 5) par ex, ce qui donnerait RSI=70 =>0, RSI=50 => 100, RSI=30 => 200 (mais on limiterait à 100 max). On affinera ces règles. - Pour les followers Twitter : distribution large, on peut faire un log également. Et tenir compte non seulement du nombre absolu mais de la croissance récente (par ex, une crypto qui double ses followers en un mois pourrait avoir un bonus). - Pour les commits GitHub : on peut prendre le nombre de commits sur 3 mois, le nombre de contributeurs, etc., et faire un score relatif. Par ex, si un projet a 100 commits sur 3 mois c’est excellent (score 100 si c’est le max du corpus), alors que 0 commit = score 0. - Pour la TVL : on peut normaliser par le plus grand TVL (Ethereum DeFi si on inclut, ou le protocole DeFi #1). On prendra log10(TVL) sur log10(max TVL). - Pour des indicateurs booléens (ex: “a eu un audit de sécurité ?”), on peut accorder une certaine note si oui, 0 si non, et ça fera partie du calcul sécurité.
La spécification détaillera par métrique la formule. Pour concision ici, on pose le principe que chaque catégorie aura ses sous-métriques et que chacune est normalisée sur 0-100. Ensuite la catégorie elle-même est souvent une moyenne pondérée de ses sous-métriques. Par exemple : - Score Communauté = 50% score_followers_twitter + 30% score_croissance_twitter + 20% score_autres (ex: Reddit). - Score Liquidité = 40% volume, 40% marketcap, 20% nombre_exchanges (les pondérations internes pourront être ajustées). Ces pondérations internes seront calibrées en phase de tests/validation pour que les scores fassent sens (section tests).
4.2 Calcul des scores par catégorie
Une fois chaque paramètre normalisé, on calcule les scores de catégorie. Pour chaque catégorie, on liste les paramètres qui y contribuent : - Communauté : nombre de followers Twitter, croissance (% ou absolue) sur 30j, éventuellement engagement (moyenne des retweets/like par tweet récent). On pourrait aussi inclure le nombre de membres Reddit ou Telegram si disponibles. Ces facteurs combinés donnent une note. Ex : on pourrait calculer un score social global = (Score_followers + Score_croissance + Score_engagement) / 3 pour simplifier. - Liquidité : paramètres principaux : market cap (plus c’est élevé, plus c’est liquide en général), volume 24h (un volume élevé indique qu’on peut entrer/sortir sans trop impacter le prix), nombre de marchés (exchanges) listant le token, et pourquoi pas profondeur moyenne des carnets (mais on n’a pas ces données facilement, on approximera via volume). On combine ces éléments. On donnera un poids un peu plus fort au volume relatif (car un market cap élevé sans volume peut indiquer une baleine illiquide). - Opportunité : paramètres orientés trading/momentum : RSI, variation 7j ou 30j du prix (un actif qui a beaucoup baissé récemment peut représenter une opportunité de rebond, donc on peut noter plus haut, ou inversement on peut considérer qu’une tendance haussière est opportunité car momentum positif – c’est subtil et dépend de la stratégie). On peut aussi inclure l’indicateur de trending (est-ce que cette crypto fait partie des plus mentionnées actuellement ? Si oui opportunité car hype, ou au contraire attention bull trap… mais en score opportunité on peut valoriser le hype modérément). Une approche : ScoreOpp = moyenne de (Score_RSI_technique, Score_Hype). Score_RSI_technique on l’a esquissé, Score_Hype pourrait venir du rang de la crypto dans les trending (ex: top trending = 100, pas trending = 0, ou basé sur croissance volume). On calibrera pour que ce score détecte les situations potentiellement profitables. - Sécurité : plus délicat quantitativement. On peut au début se baser sur des critères comme l’ancienneté du projet (un projet ancien non hacké peut gagner des points), la taille de la communauté de développeurs (plus de devs = code plus scruté), éventuellement la distribution du hashrate (si PoW) ou du staking (si quelques validateurs = moins sécure). On pourrait aussi utiliser un proxy : par exemple, CoinGecko ou d’autres ont un “Trust Score” pour les exchanges, mais pas directement pour les projets. Il existe des audits ou certifications (CertiK par ex donne des scores de sécurité). Si possible on pourrait intégrer une API ou dataset d’audits (cependant pas trivial). Pour l’instant : ScoreSécurité = f(temps depuis lancement + présence audits + décentralisation). Par ex, on donne +20 si audité, +X en fonction du nombre de validateurs (on aura du mal à avoir ce chiffre pour chaque L1, sauf via une base externe). Possiblement on traitera différemment selon type de projet (pour une dApp DeFi, la TVL elle-même n’est atteinte que si le marché fait confiance = certain niveau de sécurité perçu). On notera comme contrainte qu’il faudra améliorer ce score avec le temps et des sources de données plus riches. - Technologie : basé sur l’activité de développement open-source. On peut calculer ScoreTech = (Score_commits + Score_contributeurs + Score_release) / 3. Commits on normalise par rapport au projet le plus actif (ex: Ethereum, Polkadot sont très actifs donc 100). Contributeurs pareil (Bitcoin, Ethereum ont des centaines de contributeurs). Un projet avec 1 dev part-time aura proche de 0. On fait attention que certains projets ne mettent pas tout sur GitHub (si fermé ou sur GitLab par ex). Dans ce cas on n’aura pas de données => on devra possiblement marquer comme N/A et pénaliser le score (ou le calculer sur ce qu’on a). - Tokenomics : on utilisera des critères comme l’inflation annuelle du token (faible inflation ou token deflationniste = bon -> on peut dire Score_inflation = 100 si inflation <2%, score plus bas si inflation forte ou supply illimitée), la concentration des richesses (si on peut obtenir le % détenu par les 10 plus grosses adresses via par ex. CoinGecko qui parfois donne un “holder concentration”), la présence de mécanismes de burn ou de redistribution. Beaucoup de ces données ne sont pas facilement via API publiques, donc on peut simplifier : ScoreToken = (Score_inflation + Score_distrib) / 2. Score_distrib on peut approximer en prenant le ratio “market cap / fully diluted cap” – si c’est proche de 1, ça veut dire que la plupart des tokens sont déjà en circulation (bon point car pas de forte dilution à venir). Si c’est 0.1, ça veut dire que seulement 10% des tokens sont circulants, donc attention déblocage futur : on donne un score faible. On peut aussi inclure la liquidité sur DEX (ex: taille des pools) comme indicateur de tokenomics (liquidité on l’a mis déjà, donc non).
Une fois chaque catégorie calculée, le système stocke ces valeurs arrondies (ou en décimal).
4.3 Calcul du score global (pondération par défaut)
Le score global par défaut sera une moyenne pondérée des 6 scores de catégories. Les pondérations seront initialement définies en collaboration avec l’équipe ou sur des bases d’expérience. Par exemple, on pourrait démarrer avec une pondération égale (chaque catégorie 1/6, donc ~16.7% chacune) pour ne favoriser aucun aspect en particulier. Toutefois, il est possible que certaines catégories méritent plus de poids que d’autres selon la philosophie du scoring : - On pourrait considérer que la Sécurité et la Technologie sont fondamentales pour éviter les arnaques, donc leur donner un poids plus fort, disons 20% chacune, et répartir 60% restant entre les 4 autres (15% chacune). - Au contraire, si on veut un score global qui reflète l’attrait global, on peut équilibrer également.
Pour le moment, on posera l’hypothèse d’un poids égal pour chaque catégorie (≈16.7%). Ces pondérations par défaut seront documentées et pourront être ajustées plus tard si on remarque qu’elles donnent un meilleur résultat (par exemple via des tests de corrélation entre score et évolution future du prix, on pourrait affiner).
La formule de score global (par défaut) est donc :
〖"ScoreGlobal" 〗_"defaut" =w_C⋅Score_Comm+w_L⋅Score_Liq+w_O⋅Score_Opp+w_S⋅Score_Sécu+w_T⋅Score_Tech+w_K⋅Score_Token
avec w_C=w_L=...=w_K=1/6 initialement (ou autre distribution décidée).
Ce calcul sera effectué par le back-end au moment de l’ingestion quotidienne (après calcul des scores caté). Le résultat sera arrondi (probablement à l’entier près ou une décimale près pour affichage, mais stocké en base avec plus de précision possiblement).
4.4 Application des pondérations personnalisées
Comme décrit en 1.5, lorsqu’un utilisateur choisit des pondérations personnalisées w'_C,w'_L,...,w'_K (qui seront normalisées pour sommer à 1), le score global personnalisé est calculé par la même formule en remplaçant w par w' .
Deux modes de calcul peuvent être envisagés : - Calcul à la demande à chaque requête : l’utilisateur envoie ses pondérations, le back-end recalcule à la volée les scores globaux de toutes les cryptos selon ces poids (en multipliant simplement chaque score catégorie en base par le poids, puis sommation). C’est très léger computationalement (quelques milliers d’opérations). On peut le faire à chaque fois que l’utilisateur bouge un slider (mais ça ferait beaucoup de requêtes) ou lorsqu’il clique appliquer. - Précalc selon profils : s’il y a des profils type enregistrés, on pourrait même stocker des scores globaux pour différents profils. Mais vu la liberté offerte, mieux vaut calculer à la volée.
Le recalcul doit toutefois tenir compte de l’historique si on veut afficher des graphiques personnalisés : pour cela, soit on recalcule côté client en récupérant l’historique de chaque score catégorie (ce qui fait beaucoup de données), soit on a un endpoint pour l’historique personnalisé qui recalcule serveur. Par simplicité initiale, on pourrait ne pas permettre l’historique custom (juste recalculer le score global actuel custom). Mais ce serait un plus de pouvoir voir “si j’avais utilisé mes pondérations, comment ce projet se serait comporté dans le passé”. Ce calcul est réalisable car on stocke tous les scores catégories historiques, donc c’est la même formule appliquée sur ces tables.
En tout cas, la précision du calcul restera la même (on s’assurera d’éviter les erreurs d’arrondi en normalisant bien). Et on explicitera sur l’UI quels poids sont en vigueur pour un score global affiché (ex: “Score Global (personnalisé)” vs “Score Global (par défaut)”).
4.5 Transparence et évolution du moteur de scoring
Afin d’instaurer la confiance, la méthodologie de scoring sera transparente pour l’utilisateur final : nous publierons les grandes lignes (voire formules détaillées) de comment chaque catégorie est calculée. Par exemple, expliquer que le score Communauté dépend principalement du nombre de followers Twitter, etc. Cela sera dans la documentation (et potentiellement en open source plus tard). En effet, comme mentionné auparavant, des plateformes comme CoinCheckup attribuent des scores via des formules qu’ils ont fini par promettre de publier[22], signe que la transparence est un atout pour crédibiliser le score.
Le moteur de scoring sera conçu de manière modulaire afin de pouvoir ajuster les paramètres et formules sans tout casser. Par exemple, toutes les pondérations (qu’elles soient celles des catégories ou celles à l’intérieur d’une catégorie) seront définies dans un fichier de configuration central ou une table de paramètres, pour pouvoir les modifier facilement (plutôt que d’être hard-codées).
Des ajustements pourront survenir lorsque, par exemple, on se rend compte qu’une métrique est trop prise en compte ou pas assez. Un plan de mise à jour est prévu (section 8) pour recalibrer si besoin.
Enfin, on pourrait implémenter à terme un système de notation relative : c’est-à-dire plutôt que d’avoir un score absolu, positionner le projet par rapport aux autres. Mais le format actuel (score sur 100) est plus parlant au grand public, donc on le garde.
5. Gestion des utilisateurs et authentification
5.1 Comptes utilisateurs et rôles
Le site sera accessible en lecture à tous (publique) sans nécessité de créer un compte pour consulter les scores de base. Cependant, certaines fonctionnalités seront réservées aux utilisateurs inscrits : - Personnalisation des pondérations et sauvegarde de celles-ci. - Création d’une watchlist. - Éventuellement accès complet à l’export de données (on pourrait autoriser un export partiel aux non-inscrits, mais pour des exports complets de l’historique on peut requérir un compte afin de ne pas surcharger anonymement). - Participation à une future communauté (commentaires, etc., si implémenté plus tard).
Les comptes utilisateurs contiendront un e-mail (identifiant), un nom d’utilisateur/pseudonyme (pour affichage ou éventuelles interactions sociales futures), et un mot de passe stocké de façon sécurisée (hachage bcrypt ou équivalent). Le processus d’inscription nécessitera a minima une validation de l’email (envoi d’un lien de confirmation) pour éviter les bots et pouvoir communiquer d’éventuelles alertes ou newsletters.
On implémentera potentiellement deux types de rôles : - Utilisateur standard. - Admin (compte administrateur) – ce dernier aura accès à des outils d’administration non exposés au public, par ex. une interface pour re-calculer tous les scores manuellement, visualiser les logs, gérer le contenu méthodologique, etc. Ce n’est pas indispensable pour MVP, mais on le prévoit.
5.2 Authentification et sécurité
Le système d’authentification sera probablement géré via le back-end Python (surtout si on utilise Django qui l’a en natif). Sur une API REST pure, on pourrait opter pour une authentification par token JWT : à la connexion réussie, le serveur envoie un token signé que le client stocke (par ex. dans localStorage) et renvoie dans les headers Authorisation à chaque requête aux endpoints protégés. Avantage : le front-end SPA peut ainsi rester stateless côté serveur. Inconvénient : il faut gérer le rafraîchissement de token éventuellement.
Une alternative plus simple en contexte web classique : utiliser la session HTTP (cookie de session sécurisé). Synology Web Station utilise Nginx, donc on peut gérer les sessions au niveau app. Django par ex gère des cookies de session par défaut, ce qui permet d’utiliser facilement request.user dans l’API pour vérifier l’auth. On peut combiner ça avec un token CSRF pour les requêtes POST.
Quoi qu’il en soit, on s’assurera d’utiliser HTTPS (le NAS Synology permet d’installer un certificat SSL Let’s Encrypt facilement via son interface) pour chiffrer les échanges, notamment les identifiants et tokens.
Les mots de passe seront hashés (bcrypt ou Argon2 idéalement, Django propose Argon2 out of the box en config). Une politique de mot de passe fort sera encouragée (min 8 caractères avec mélange). Un système de récupération de mot de passe via email sera mis en place (un endpoint pour demander reset, envoi d’un lien token à durée limitée, etc.).
Nous limiterons les tentatives de login bruteforce via un mécanisme de rate limiting sur l’endpoint auth (par ex. pas plus de 5 essais par 15 minutes par IP), et en cas d’éventuelles fonctions sensibles (non prévu ici, mais ex: changer email), on demandera reconfirmation du mot de passe.
5.3 Gestion des préférences utilisateurs
Une fois connecté, l’utilisateur a accès à sa page Profil où il peut : - Modifier ses informations de compte basiques (email, pseudo, mot de passe). - Gérer ses préférences de scoring : c’est ici qu’il pourra ajuster et enregistrer ses pondérations par catégorie (comme décrit section 3.5). Ces pondérations seront sauvegardées en base. Lorsqu’il se reconnectera, le front-end récupérera ces paramètres et pourra directement afficher les scores personnalisés selon son profil s’il le souhaite (soit automatiquement, soit via un bouton “appliquer mon profil”). - Gérer sa watchlist : simple liste de cryptos favorites. On peut l’implémenter comme une liste d’IDs de cryptos stockée en base reliée à l’utilisateur. Sur l’UI, on pourrait ajouter une ⭐ à côté du nom d’une crypto pour l’ajouter/enlever des favoris. Sur la page profil, on liste ses favoris et on permet de les réordonner ou supprimer. La watchlist pourrait être affichée en page d’accueil pour l’utilisateur (par ex. un petit tableau en haut montrant juste ses coins favoris et leurs scores actuels). Cela améliore l’expérience personnalisée.
5.4 Accès invité vs connecté
Sans compte (mode invité), on accède en lecture seule aux pages publiques : tableau principal, trending, détail crypto, méthodologie. Les fonctionnalités suivantes inviteraient à se connecter ou s’inscrire si tenté en invité : cliquer “❤️ Favori” ou “💾 Enregistrer pondérations” afficherait un pop-up “Créez un compte pour utiliser cette fonctionnalité”.
On pourrait laisser l’invité jouer avec les pondérations de manière temporaire (car c’est calculé client ou serveur sans stockage) afin de lui montrer la puissance de l’outil, mais pour sauvegarder sur la durée il devra créer un compte. De même, il peut cocher des cryptos et comparer sans compte (ce n’est pas une action qu’on doit restreindre, c’est juste de la lecture), donc la comparaison reste ouverte.
En termes de quotas, on pourrait imposer aux invités certaines limitations (par ex. pas plus de X exports par jour) pour encourager la création de compte, mais c’est un choix produit.
5.5 Administration et modération
En dehors du scope utilisateur standard, on mentionne l’existence potentielle d’un compte administrateur (non obligatoire dès le début, mais utile). Ce compte pourrait accéder à une interface cachée (non listée dans le menu pour les non-admin) permettant de : - Voir la liste des utilisateurs inscrits, éventuellement bannir un utilisateur malveillant (peu probable à ce stade). - Forcer le recalcul des scores (par ex, si on a ajusté une formule et qu’on veut recalculer tout l’historique). - Modifier les pondérations par défaut globales ou désactiver temporairement la collecte (mode maintenance). - Consulter les logs d’erreurs du backend depuis l’UI (sinon on le fera en SSH sur le NAS). - Mettre à jour la liste des cryptos suivies (par ex ajouter un nouveau symbole trending manuellement si besoin, ou recharger la liste top 1000). - Gérer le contenu de la page méthodologie (si c’est dynamique).
Ce module d’admin peut être développé plus tard ou être rudimentaire (même un simple accès à adminer/phpMyAdmin pour l’admin technique pourrait suffire).
6. Mise en place de l’environnement sur NAS Synology
6.1 Configuration matérielle et OS
Le NAS Synology hébergeant l’application devra disposer de suffisamment de ressources (CPU, RAM, stockage) pour supporter un serveur applicatif et la base de données. Un modèle milieu de gamme à base de CPU x86_64 avec au moins 4 Go de RAM est recommandé pour de bonnes performances web et ETL.
Le système DSM (DiskStation Manager) fournit un environnement Linux customisé. On utilisera le Service Web Station de DSM pour la partie serveur web. Web Station permet d’exécuter des applications web via Nginx ou Apache. On choisira Nginx comme back-end HTTP (plus performant et support natif via Synology).
On installera via le Centre de paquets Synology : - Python 3.x : Synology fournit un package Python (il faudra vérifier la version, idéalement 3.9+). On l’installera, cela permettra d’utiliser uWSGI via Web Station[18]. - MariaDB 10 : à installer et configurer (définir mot de passe root, créer un utilisateur et base dédiés à l’application). - phpMyAdmin (optionnel, pour l’administration facile de MariaDB). - Git (Synology propose peut-être un paquet Git ou on peut utiliser git via CLI si accessible). - Docker : si on choisit la voie Docker, installer le paquet Docker et gérer ensuite via Portainer ou SSH.
6.2 Déploiement de l’application Python
Deux scénarios en fonction de l’approche choisie : - Sans Docker (uWSGI) : On préparera l’application Python localement (ou sur le NAS lui-même) et on la placera dans le répertoire web du Synology (souvent /web/ ou un vhost spécifique). Via Web Station, on créera un Virtual Host pointant sur ce répertoire, en sélectionnant Python comme langage de script et le profil uWSGI Python créé dans les paramètres[19]. On devra fournir le fichier WSGI d’entrée, généralement un fichier .py qui définit l’application (ex: app = create_app() pour Flask, etc.)[23]. On testera avec un “Hello World” d’abord pour valider la configuration (car débugger sur Synology peut être fastidieux sans logs, mais l’article Medium fourni des astuces de log[24][25]). On veillera à ce que toutes les dépendances Python requises soient installées. Web Station offre la possibilité d’uploader un requirements.txt lors de la création du profil Python, qui va installer les packages dans l’environnement du NAS[26]. On l’utilisera en y listant Flask/FastAPI, SQLAlchemy, pandas (peut-être pour ETL), requests, etc. Il faudra possiblement ajuster la configuration de uWSGI (threads, processus). - Avec Docker : On crée un fichier Docker Compose ou on utilise Portainer. On aura un conteneur pour l’app (Dockerfile from python:3.10, copy code, pip install deps, expose port 8000 par ex). On aura un autre conteneur pour la DB (mariadb:latest with volume for data, environment for root password). On configurerait un reverse proxy (Synology peut rediriger le port 443 vers un port de container ou on utilise un container Nginx). Synology DSM7 permet d’associer un nom de domaine et de router vers un container via son interface “Reverse Proxy”. Cette approche bien qu’un peu plus lourde en setup, isolera bien l’app.
Dans les deux cas, on configurerait le domaine (par ex cryptoscore.local ou un vrai nom de domaine pointant vers l’IP du NAS) via DNS. Sur le NAS, on utiliserait Let’s Encrypt via l’interface DSM Security > Certificat pour obtenir un certificat SSL pour ce domaine, et on l’associera au Virtual Host ou au Reverse Proxy. Ainsi, on aura du HTTPS.
6.3 Stockage des données sur le NAS
Les données de la base MariaDB seront stockées sur le volume du NAS. On fera en sorte de stocker dans un dossier régulièrement sauvegardé (Synology propose HyperBackup ou au moins des snapshots). On configurera aussi la base pour accepter des connexions uniquement locales (par sécurité). L’application Python, si conteneur Docker, se connectera à mariadb container via un réseau interne, ou si via host, on peut utiliser localhost:3307. On aura activé le TCP/IP sur MariaDB (via DSM > MariaDB > activer TCP, comme mentionné dans documentation Synology[11]).
Niveau sécurité : on créera un utilisateur SQL dédié avec uniquement les permissions nécessaires sur la base de l’application, au lieu d’utiliser root.
6.4 Sécurité de l’environnement
Le NAS étant potentiellement exposé sur internet, on doit durcir la sécurité : - Pare-feu Synology : Configurer le firewall de DSM pour n’ouvrir que les ports nécessaires : 80/443 pour le web, et éventuellement 22 pour SSH si besoin d’accès admin (mais mieux vaut via VPN ou restreint IP). MariaDB port 3307 n’a pas besoin d’être ouvert en externe. - Certificat SSL : comme dit, on activera HTTPS. Forcer les connexions en HTTPS (Redirection HTTP->HTTPS via l’hôte virtuel). - Mises à jour DSM : Maintenir le DSM du NAS à jour ainsi que les paquets (notamment patchs de sécurité de MariaDB, etc.). Idéalement activer les mises à jour auto de sécurité. - Isolation : Si possible utiliser un compte non admin sur le NAS pour exécuter les processus web (Web Station le fait probablement avec user http ou personne dédiée). - Clés API : on l’a déjà mentionné, stocker hors du code (fichier config non accessible web, ou variables env via l’interface Synology – par exemple dans Web Station on peut config un param WSGI ou utilise un .env dans le dir non exposé). - Monitoring Synology : activer les alertes mails du NAS en cas de détection d’accès anormal, etc. - Limitation ressources : Sur Docker, mettre des limites CPU/mémoire si on craint qu’une boucle ETL partie en vrille ne consomme tout. Sur uWSGI, définir un nombre max de worker raisonnable pour pas saturer la RAM.
6.5 Outils et librairies Python
Liste non exhaustive des librairies que nous utiliserons dans l’environnement Python : - Framework web : Flask (avec Flask-RESTful ou FastAPI). Supposons qu’on choisisse Flask pour sa simplicité. Flask + éventuellement flask_cors (pour permettre les requêtes du front-end si hebergé ailleurs ou même sur autre port). - ORM : SQLAlchemy pour interagir avec MariaDB, ou l’ORM de Django si Django. Si Flask, on peut utiliser SQLAlchemy ou un micro-ORM comme peewee. SQLAlchemy est standard et permet de définir nos classes modèle pour Crypto, Score, etc. - Clients API : la bibliothèque standard requests pour faire les appels HTTP aux API externes. Eventuellement aiohttp si on veut rendre les appels asynchrones (pour gagner du temps en lançant plusieurs en parallèle), mais il faudra alors que l’ETL soit dans un contexte async ou threads. On peut plus simplement utiliser du threading concurrent.futures pour appeler plusieurs API en parallèle (ex: 4 threads pour 4 appels CoinGecko simultanés). - Traitement de données : pandas peut aider pour manipuler les données de marché, calculer RSI, etc. Cependant, charger pandas (lourd) sur le NAS juste pour RSI est peut-être overkill. On peut calculer RSI “à la main” via une petite fonction Python si on a les données de prix historiques. On pourrait donc ne pas prendre pandas si on optimise la mémoire. A voir selon commodité. - Librairie pour graphiques : côté serveur pas besoin (tout sera fait côté client via JS). - Autres : python-dateutil pour gérer les dates facilement, schedule ou APScheduler pour l’ETL planifié (si on ne s’appuie pas sur cron externe), pyyaml si on utilise des fichiers YAML de config, bcrypt pour le hash des passwords (si Flask), ou la lib d’auth Django etc.
Le tout sera listé dans requirements.txt.
Déploiement : on pourra soit installer les libs via pip en ligne de commande sur le NAS (si pip dispo), soit via l’interface Web Station comme mentionné. On testera en environnement de dev (peut-être sur un PC ou VM Linux) l’application avant portage sur NAS.
7. Protocoles de tests
Pour assurer la qualité et la fiabilité du système, nous définirons plusieurs niveaux de tests :
7.1 Tests unitaires
Chaque composant critique du back-end fera l’objet de tests unitaires en Python (en utilisant unittest ou pytest). En particulier : - Les fonctions de calcul de score pour chaque catégorie : on créera des scénarios simulés (ex: un projet avec certaines valeurs extrêmes) pour vérifier que le score produit est cohérent (ex: un projet avec la plus grosse communauté doit avoir Score Communauté ~100, etc.). On testera les formules de normalisation (ex: fonction de scoring du RSI) pour s’assurer qu’elles donnent les valeurs attendues (70 -> 0, 30 -> 100 dans notre conception par ex)[4]. - La combinaison en score global : test d’une pondération personnalisée simple (ex: mettre tout le poids sur une catégorie, le score global doit alors être égal au score de cette catégorie). - Les modules d’intégration API : on simulera des réponses de l’API CoinGecko, etc., via des mocks, pour vérifier que la fonction de collecte parse correctement et insère en base ce qui est attendu. Par exemple, simuler une réponse JSON de CoinGecko avec 2 cryptos et voir si notre code crée 2 enregistrements Score bien formés. - Tests des modèles et requêtes : vérifier que les ORM renvoient bien les données attendues. Par exemple, ajouter des scores en base via l’ORM dans un test, appeler la fonction d’API interne (contrôleur) qui génère la réponse JSON, et vérifier le format et les valeurs du JSON. - Tests utilitaires : fonctions de calcul de RSI (donner une série de prix connue et vérifier le RSI calculé est correct en comparaison d’une valeur de référence calculée manuellement), etc.
On vise une couverture de code significative sur la partie calcul ( > 80% sur le module scoring par ex). Les tests seront idéalement exécutés automatiquement à chaque mise à jour de code (intégration continue, si configurée via Gitlab CI ou autre).
7.2 Tests d’intégration
Les tests d’intégration vérifieront que les différentes couches interagissent correctement : - Déployer l’application sur un environnement de test (par ex. sur le NAS en local ou sur une VM) et exécuter des requêtes API end-to-end : par exemple, peupler la base de quelques données de test, puis appeler via HTTP l’endpoint /api/cryptos et vérifier que la réponse JSON a bien la structure attendue et les données correspondantes. - Test d’un cycle complet de l’ETL : on pourra créer un mode “test” du script de collecte qui lit des fichiers mock au lieu d’appeler les vraies API (pour ne pas consommer de quota) et voit si tout le pipeline (appel -> transformation -> stockage -> recalcul des scores -> dispo via API) fonctionne. - Tests de l’interface utilisateur : dans la mesure du possible, on peut écrire des tests end-to-end avec des outils comme Selenium ou Playwright. Par exemple, ouvrir le site dans un navigateur automatisé, essayer de cliquer sur tel filtre et vérifier que le tableau se filtre bien (en examinant le DOM rendu). C’est assez coûteux à mettre en place mais très utile pour s’assurer que l’UX fonctionne. - Test multi-navigateurs : on fera des tests manuels ou via BrowserStack sur les principaux navigateurs (Chrome, Firefox, Safari, Edge) et devices (desktop vs mobile) pour s’assurer du rendu responsive et de l’absence de bug spécifique (ex: vérifier que le tableau scroll bien sur mobile, etc.).
7.3 Tests de performance et de charge
Étant une application de data, il est important qu’elle supporte une charge raisonnable sans ralentissement notable. On conduira des tests de charge à plusieurs niveaux : - Charge backend : Simuler un certain nombre de requêtes API concurrentes. Par ex, utiliser ab (ApacheBench) ou JMeter pour envoyer 100 requêtes/s sur /api/cryptos et voir à quel point le serveur tient, en mesurant le temps de réponse moyen, et vérifier qu’il reste < par ex 200 ms. Si ce n’est pas le cas, on examinera où ça coince (requêtes DB pas assez optimisées, etc.). - Charge base de données : Tester la rapidité de certaines requêtes lourdes, par ex l’extraction de l’historique sur 5 ans d’une crypto. Si c’est lent (>2s), on envisagera des index ou refactor (par ex, charger les données différemment). - Charge front-end : Mesurer le poids de la page initiale, et le temps de chargement sur une connexion standard. On utilisera les DevTools (Lighthouse) pour vérifier qu’on a de bonnes notes de performance (minification, compression Gzip/ Brotli activées, mise en cache statique de fichiers JS/CSS/images via en-têtes). On optimisera si besoin (par ex, chargement différé des graphiques quand l’élément est visible, etc.). - Scénario usage intensif : Simuler un utilisateur qui change rapidement les filtres, les pondérations, etc., pour voir si l’application suit sans fuites de mémoire (surtout côté front-end, on surveillera la console pour d’éventuelles erreurs). Côté backend, s’assurer que recalculer 1000 scores plusieurs fois par seconde (dans le pire cas où plein d’utilisateurs testent des pondérations en même temps) ne surchage pas le CPU du NAS. En pratique, 1000 scores * quelques opérations – c’est léger, mais on testera par précaution.
On fixera des objectifs de performance : idéalement, <1 seconde pour afficher la page principale avec les 1000 scores (après chargement initial), <100 ms pour répondre à une requête API simple depuis le serveur (hors latence réseau), possibilité de supporter au moins 50 utilisateurs simultanés sans dégradation notable (c’est arbitraire, on peut adapter selon l’attendu du trafic). Si la cible est potentiellement plus large, on envisagera plus tard du caching ou un mode statique partiel.
7.4 Tests de sécurité
On effectuera également des tests relatifs à la sécurité applicative : - Tests d’injection SQL : essayer via l’API d’envoyer des caractères spéciaux dans les paramètres (notamment sur les endpoints qui pourraient filtrer par symbole ou autres) pour s’assurer que l’ORM paramétré gère bien la protection (ce qui est généralement le cas). - Tests XSS : vérifier que toutes les données affichées dans l’UI (qui peuvent provenir de l’extérieur, par ex un nom de crypto étrange) sont bien échappées. Comme on contrôle la source (APIs officiels, peu probable qu’un nom de crypto contienne du script malveillant, mais par précaution). - Tests CSRF : s’assurer que les actions sensibles (login, etc.) sont protégées contre une soumission cross-site. Si on part sur JWT, moins un souci, si cookie de session, il faudra un token CSRF. - Scan de vulnérabilités : utiliser des outils ou services (OWASP ZAP, ou un scanner en ligne) pour détecter si des ports ouverts ou config mal faite sur le NAS. - Tests d’autorisation : vérifier que les endpoints protégés ne sont réellement pas accessibles sans token (par ex, appeler /api/user/settings sans auth doit renvoyer un code 401), et qu’un utilisateur ne peut pas accéder aux données d’un autre (ex: essayer de demander la watchlist d’un autre user via l’API en changeant un ID, doit être interdit côté serveur). - Pentest externe : éventuellement, faire relire la config sécurité, ou demander à une personne tierce d’essayer de casser le système (dans un cadre contrôlé).
7.5 Tests de déploiement et de récupération
Enfin, on testera le processus de déploiement sur le NAS : - Scripts d’installation, configuration du virtual host, etc., en partant d’un NAS vierge, pour vérifier que la documentation d’installation (section 8/9) est correcte. - Tests de sauvegarde/restauration : simuler un crash ou perte de données et utiliser une sauvegarde DB pour restaurer, s’assurer que l’application redémarre bien. - Tests de montée de version : par ex, si on met à jour la structure de la DB (migrations), tester l’application après migration (peut impliquer d’intégrer Alembic ou Django migrations). - Tests de la planification ETL : par ex, planifier la tâche sur Synology et vérifier qu’elle s’exécute bien à l’heure dite (en scrutant les logs de notre app ou un flag en DB).
Les résultats de ces tests seront documentés, et on mettra en place un plan d’action pour toute défaillance découverte.
8. Maintenance, monitoring et plan de mise à jour
8.1 Maintenance courante et supervision
Une fois en production, l’application devra être régulièrement surveillée pour s’assurer de son bon fonctionnement : - On mettra en place un monitoring basique : par exemple, intégrer un système de logs et d’alerte. Le back-end Python journalisera les événements importants (collecte réussie ou échouée, erreurs d’appel API, etc.) dans un fichier de log sur le NAS. On configurera Synology Log Center ou un système Syslog pour capter ces logs. Le tutoriel Synology suggère de rediriger les logs Python vers Syslog[25][27], ce qui permettrait d’utiliser l’interface Log Center du NAS pour surveiller. - Des alertes email peuvent être configurées : par exemple, si la collecte quotidienne n’a pas pu se faire (absence de nouvelles données à telle heure), envoyer un email à l’admin. Idem en cas d’erreurs critiques dans l’application (on peut intercepter les exceptions non gérées via un middleware et envoyer un mail). - Sur le plan système, Synology envoie déjà des alertes si un volume est plein, etc. On surveillera l’espace disque car stocker des historiques de données pourrait prendre de l’espace (mais texte et chiffres, ce n’est pas énorme comparé à des médias). - Monitoring de performance : on pourrait installer Netdata ou Grafana + Prometheus via Docker pour avoir un œil sur l’UC, la RAM, etc., du NAS en temps réel. Au minimum, on consultera régulièrement l’utilisation CPU/RAM via DSM (surtout lors de la tâche ETL, vérifier que ça ne sature pas). - Plan de backup : On script un dump quotidien de la base de données (mysqldump) vers un dossier du NAS, que Synology peut ensuite synchroniser vers un stockage cloud ou un disque externe. Ainsi en cas de crash du NAS ou de corruption de base, on peut restaurer. On peut conserver par ex 7 jours de backups tournants pour limiter la taille.
8.2 Mises à jour de l’application
Nous prévoirons un processus pour déployer les mises à jour (nouvelles versions du code, ajustements de formules) de manière maîtrisée : - En environnement non Docker : on versionnera le code (Git) et on fera des pulls sur le NAS. Possiblement, on pourra installer Git sur le NAS et cloner le dépôt dans le dossier web. Pour déployer une nouvelle version, il suffira de faire git pull et de redémarrer le service uWSGI (peut-être un redémarrage du profil Python ou du NAS, ou tuer le process pour qu’il se relance). On documentera ces étapes. - En Docker : on build une nouvelle image (via CI ou local) et on la déploie via Docker (arrêt du container ancien, lancement du nouveau). Synology permet le déploiement via Portainer ou sa UI Docker. Ce process sera scripté autant que possible pour minimiser le downtime. - Migrations de base de données : si on modifie le schéma (ex: ajouter un champ, une table), on utilisera un système de migration (Alembic ou Django migrations) pour appliquer le changement en prod. On testera la migration sur un dump avant. Durant la maintenance, on peut mettre le site en mode lecture seule ou down quelques instants (afficher un message “Maintenance en cours” via une page statique configurée dans Nginx). - Fréquence des mises à jour : on s’attend à faire des ajustements surtout au début (phase de calibration) puis moins fréquemment. Un plan de versioning (v1.0, 1.1 etc.) sera suivi. On attendra des retours utilisateurs ou des besoins (ex: ajout d’une nouvelle catégorie ou nouveau paramètre) pour planifier une release.
8.3 Mise à jour des sources de données et API
Les sources externes (APIs) peuvent changer (nouvelles versions, dépréciation). Il faudra surveiller : - CoinGecko : ils ont introduit en 2024 l’obligation de clé API pour usage intensif[12]. Si d’autres changements adviennent (endpoints modifiés), on adaptera le code. On suivra leurs annonces (via leur blog ou forum). - CoinMarketCap : idem, garder un œil sur la limite mensuelle ou sur d’éventuels changements de politique de gratuit. - Twitter API : situation évolutive, potentiellement on pourrait migrer vers une autre source (ex: X (Twitter) propose du scraping par HTML ou via des data providers). - GitHub API : peu probable que ça change radicalement, mais on respectera les limites (s’assurer de ne pas atteindre 5000 calls/h, logguer combien on en fait). - Nouvelles API : Si l’on décide d’intégrer par ex une API d’audit (CertiK, etc.), on l’ajoutera prudemment et on testera sur dev d’abord.
On maintiendra une documentation technique à jour pour que l’équipe sache comment sont configurées ces intégrations (clés, endpoints).
8.4 Évolutivité et scalabilité
Si l’application gagne en popularité (beaucoup d’utilisateurs simultanés, plus de données à traiter), nous avons quelques options sur le NAS : - Augmenter la RAM du NAS (certains modèles permettent). - Optimiser le code et les requêtes (ajout de caches). Par exemple, mettre en place un cache en mémoire (Redis via Docker) pour stocker la réponse JSON du top 1000 pendant 1 minute, de sorte que si 100 utilisateurs la demandent en même temps, on ne requête la DB qu’une fois par minute. - Si le NAS atteint ses limites, envisager de migrer l’application vers un serveur cloud ou une machine plus puissante. On pourrait alors toujours utiliser Synology comme stockage de backup, mais la partie web sur un VPS. Cette éventualité sera discutée si les besoins dépassent ce qui est raisonnable pour le NAS (ce qui, pour un site web consultatif, ne devrait pas arriver avant des milliers d’utilisateurs journaliers, ce qui est peut-être au-delà de l’objectif initial). - Sharding de données : improbable qu’on en ait besoin (1000 cryptos * x jours, c’est gérable sur une seule base). - Mise en place d’un CDN pour le front-end (les assets statiques comme JS/CSS pourraient être servis via Cloudflare CDN si ouvert sur internet, pour alléger la charge du NAS sur la bande passante). - Scalabilité de la collecte : si on suit plus de cryptos dans le futur (passer à top 2000 par ex), l’ETL sera plus long. Il faudra alors paralléliser davantage ou envisager de répartir sur deux machines. On peut également diminuer la fréquence de certaines données (ex: trending 100 hors top1000, on peut scanner top2000 et en extraire 100 trending – faisable).
8.5 Monitoring de l’utilisation et retours
Nous pouvons intégrer des outils pour voir comment le site est utilisé : - Analytics (Matomo auto-hébergé par ex, ou Google Analytics si on le souhaite) pour voir le nombre de visiteurs, pages vues, etc., sans violer la vie privée (on peut anonymiser IPs). - Collecter les feedbacks utilisateurs via un formulaire sur le site (“Donnez votre avis”) pour planifier les améliorations. - Surveiller s’il y a des tendances problématiques, ex: un paramètre de scoring toujours au max pour tous (signe d’inutilité), etc., et améliorer en conséquence. - Maintenir un changelog public si on modifie la méthodologie de scoring, pour que les utilisateurs sachent que quelque chose a changé (transparence).
9. Couverture logicielle et documentation
9.1 Couverture de code et qualité
Comme mentionné en section tests, on vise une bonne couverture de tests du code, en particulier pour le moteur de scoring. On utilisera un outil comme coverage.py pour mesurer le % de code exécuté par les tests. L’objectif est d’atteindre au moins 80% de couverture globale, et idéalement >90% sur les modules critiques (calculs).
Au-delà des tests, on mettra en place des outils de qualité de code : - Respect des conventions PEP8 (on peut utiliser flake8 pour analyser le code). - Type hints et éventuellement mypy pour vérifier la cohérence des types statiques. - Revue de code pair-a-pair pour chaque nouvelle fonctionnalité significative.
Ces pratiques assurent la maintenabilité à long terme, surtout si d’autres développeurs rejoignent.
9.2 Documentation à destination des développeurs
Une documentation technique sera rédigée pour faciliter la prise en main du projet par un développeur (actuel ou futur) : - README du repository : comment installer en local, comment déployer sur NAS, etc. - Schéma de la base de données : un diagramme (ex: via MySQL Workbench ou un outil en ligne) montrant les tables et relations, pour que c’est clair en un coup d’œil. - Documentation de l’API : si on utilise FastAPI, on obtient automatiquement une doc Swagger UI. Sinon, on peut écrire un document OpenAPI ou au moins lister les endpoints, paramètres et exemples de réponse. - Code comments : le code Python aura des docstrings pour les fonctions principales (notamment les formules de scoring, en expliquant la source de tel coefficient). - Méthodologie : un document (peut-être le même que celui fourni aux utilisateurs mais en plus détaillé si besoin) qui explique l’approche de scoring, les formules, et pourquoi elles ont été choisies. Cela servira de référence si un dev doit modifier une formule, pour comprendre l’intention initiale. - Guide d’administration : comment lancer manuellement la collecte, comment ajouter une nouvelle source de données, etc.
On pourrait héberger cette documentation dans un Wiki du repo ou sur un site de doc. L’important est qu’elle soit à jour et accessible facilement.
9.3 Documentation utilisateur (final)
Pour les utilisateurs finaux (souvent non techniques), on préparera : - Une FAQ sur le site, traitant des questions courantes : “Qu’est-ce que le score global ?”, “Comment est calculé le score Communauté ?”, “À quoi correspond la catégorie Opportunité ?”, “Puis-je faire confiance à ces scores ?” etc., avec des réponses pédagogiques. On y mettra des disclaimers du style “ceci n’est pas un conseil financier, faites vos propres recherches” en plus (inspiré par le disclaimer de CoinCheckup[22]). - Un guide “Comment utiliser le site” : éventuellement une visite guidée interactive la première fois (avec des bulles qui pointent les filtres, etc.), ou une page de tutoriel illustré. Comme l’UX est plutôt intuitive (tableau, filtres), ceci est optionnel, mais peut aider pour la partie personnalisations (pas courante sur d’autres sites). - La page Méthodologie publique : on y décrira de façon accessible les différentes catégories de scores, avec un petit texte par catégorie, les sources utilisées. Par exemple : “Score Technologie : mesure l’activité de développement sur le projet (commits GitHub, etc.)”. On peut mentionner que notre approche est inspirée d’autres analyses du marché (CoinGecko, etc.) qui soulignent l’importance de ces facteurs[8]. On peut même citer que la corrélation entre communauté et valeur est avérée[3] pour justifier le poids accordé à la Communauté. - Glossaire : explication de termes techniques (RSI, TVL, etc.), possiblement via des infobulles ou une section dédiée, pour les utilisateurs moins familiers.
Cette documentation utilisateur sera rédigée en français (puis éventuellement traduite si le site devient bilingue anglais).
9.4 Gestion de la configuration et du code source
On maintiendra le code source dans un système de contrôle de version (Git). On aura éventuellement deux branches principales : main (production) et dev (intégration). Les modifications seront testées sur dev puis fusionnées en main lors d’une release. On utilisera des tags de version.
La configuration du projet (notamment les secrets API) ne sera pas dans le repo bien sûr. On aura un fichier d’exemple (ex: .env.example) pour indiquer quels variables doivent être configurées.
Il serait opportun de mettre en place un environnement de staging pour tester les mises à jour avant de les pousser en prod sur le NAS. Cela peut être local ou sur une VM séparée. Étant donné les moyens limités, peut-être que l’on utilisera le NAS lui-même en double instance (pas trivial) ou plus simplement tester localement l’intégralité (en pointant sur une copie de la DB). Au minimum, beaucoup de tests automatisés comme dit plus haut pour valider avant déploiement.
10. Contraintes et considérations diverses
10.1 Contraintes des API externes
L’utilisation d’API tierces gratuites amène plusieurs limitations à bien prendre en compte : - Limites de taux (rate limiting) : On a détaillé celles de CoinGecko (30 par min, 10k/mois)[12][13] et CoinMarketCap (~333/jour)[15]. On devra coder en conséquence : implémenter des pauses ou un système de file d’attente pour ne pas les dépasser. Par exemple, si on doit faire 5 requêtes à la suite, on peut insérer time.sleep(1) entre pour étaler. - Attribution : Certaines API gratuites demandent de mentionner la source. CoinGecko requiert une attribution pour usage libre de l’API[28]. Nous devrons donc afficher quelque part (par ex en pied de page du site ou sur la page Méthodologie) une phrase du type “Données de marché fournies par CoinGecko et CoinMarketCap. Données DeFi par DeFi Llama.” pour être en règle. Éventuellement le logo CoinGecko/CoinMarketCap en petit en bas. - Qualité / disponibilité des données : Les APIs peuvent avoir des indisponibilités ponctuelles. Il faut gérer les timeouts et échecs : le code réessaiera une ou deux fois, puis si échec persistant, loguera l’erreur. On pourrait planifier une seconde tentative de collecte plus tard automatiquement. - Évolutions : comme mentionné, Twitter API est un point douloureux. On devra potentiellement adapter ou réduire la dépendance. Par ex, on peut initialement utiliser la donnée de followers fournie par CoinGecko (qui elle-même devait scraper Twitter), mais si ce n’est plus mis à jour, il faudra une autre stratégie. On surveillera aussi l’éventuel changement de Twitter (ex: X) sur les politiques. On peut aussi imaginer à terme s’abonner à des services payants si besoin et si budget. - Multiplication des sources : plus on utilise de sources, plus on multiplie le risque de problème. On priorisera d’abord une ou deux sources principales (CG, CMC) qui couvrent beaucoup. On a mentionné d’autres pour affiner (LunarCrush pour social sentiment, Glassnode on-chain), mais chaque ajout doit être justifié par un réel gain. Sinon on garde en plan d’amélioration.
10.2 Volume de données et stockage
En estimant rapidement le volume : - Top 1000 cryptos + trending 100 => ~1100 cryptos suivis. - Pour chacun, on stocke 1 enregistrement de scores par jour (7-8 valeurs numériques + ids). Disons ~200 octets par enregistrement (en comptant overhead). Sur un an : 1100365200 ≈ 80 millions d'octets = ~80 MB/an. Sur 5 ans, 400 MB. Donc très raisonnable pour le NAS. - Si on stocke aussi quelques paramètres bruts (mettons 20 nombres supplémentaires) ça double ou triple ce chiffre, mais on reste sous quelques Go sur plusieurs années. Le NAS typique a des centaines de Go ou des To, donc pas un souci. - Le plus gros pourrait être les logs texte si on logge beaucoup ou stocker l’historique complet de prix pour calculer RSI. Cependant, on n’a pas besoin de stocker l'historique complet du prix de chaque crypto en base (CoinGecko le fournit on-line si besoin). On peut stocker juste les RSI calculés. - Si on voulait stocker les prix journaliers de 1000 cryptos sur 5 ans (disons 1825 jours), c’est 1.8M points, ce qui reste petit. Mais on peut s’en passer.
Donc le volume de données n’est pas un obstacle majeur. L’important est plus la latence des requêtes sur ces tables. Avec des index sur (crypto_id, date), chercher l’historique d’un crypto est très rapide. Lister les scores du jour pour 1000 cryptos sans filtre, c’est 1000 lectures contiguës, trivial pour une DB. Donc les temps d’accès en lecture devraient être sous la ms pour la plupart des requêtes. On fera attention à l’indexation si on ajoute des filtres (ex: filtre sur score opportunité > 80 – cela implique de pouvoir requêter sur cette colonne. MariaDB le peut via index sur Score_opportunite, mais un WHERE score_opportunite>80 sur 1000 lignes n’est pas un souci. Par contre, s’il y avait 1e6 lignes, l’index serait utile).
10.3 Contraintes de latence de calcul
Le calcul quotidien de tous les scores (ETL complet) doit idéalement se faire dans un laps de temps raisonnable pour ne pas monopoliser le NAS trop longtemps ni retarder la mise à jour: - Collecter les données d’API pour 1100 cryptos : - CoinGecko : 5 appels (250 coins * 4 + trending séparé). Chaque appel peut prendre ~1-2 secondes (réseau + traitement JSON). Donc ~10 sec. - Twitter : si on évite l’API directe, on gagne du temps. Si on devait faire 1100 appels séquentiels, ce serait inenvisageable (plusieurs minutes + limites). Donc on utilisera CG. - GitHub : on va possiblement ignorer la collecte journalière et faire hebdo comme dit. Donc quotidien, on ne fait rien ou on check juste un flag. Si on faisait 1000 appels, pareil, ce serait trop lent (plus d’une minute et demie, et risque de rate limit). - DeFiLlama : 1 appel global liste ou ~1100 protocole (non, il n’y a pas 1000 protocoles DeFi, plutôt <300). Donc 1 ou quelques appels, négligeable. - Autres calculs (RSI) : calculer RSI pour 1100 cryptos signifie avoir leur prix 15 derniers jours par ex. On peut soit appeler un endpoint OHLCV de CG qui fournit l’historique en un appel par coin (ce qui referait 1100 appels, non merci). Mieux : lors de la première initialisation on peut stocker les 15 derniers jours de prix de chaque coin en base, puis chaque jour stocker le prix du jour. Ainsi on calcule RSI en utilisant les 14 jours précédents de notre base. Donc plus besoin d’appeler CG pour l’historique quotidiennement, juste initialement. - Donc RSI calcul local (quelques opérations par crypto, négligeable).
Conclusion : la collecte + calcul devrait pouvoir s’effectuer en moins de quelques minutes. Même en imaginant large, 5 min. C’est très acceptable. On peut la lancer la nuit (2h du matin par ex) pour ne pas gêner et avoir les scores frais le matin.
Si un jour on suit 10000 cryptos, là il faudrait revoir l’approche (peut-être filtrer car beaucoup de micro-coins sans intérêt, ou avoir une archi plus costaud). Mais ce n’est pas la cible actuelle.
10.4 Contraintes du Synology
Un NAS n’est pas un serveur classique, il a quelques limitations : - Puissance CPU modérée (surtout en single-core). On évitera donc les langages très lourds ou interprétés dans les boucles intenses. Python est interprété mais on est sur des volumes qui passent. On fera attention aux libs comme pandas qui peuvent consommer CPU et RAM. - Pas de haute disponibilité : si le NAS redémarre pour maj ou autre, le site sera indispo pendant ce temps. On peut accepter du downtime minime mais on planifiera les mises à jour de NAS en heures creuses. - Limitations réseau : en amont, la connexion internet du NAS (chez l’utilisateur ou bureau) peut être moins robuste qu’un datacenter (risque de coupure internet, etc.). On considère que c’est acceptable (le site est moins critique qu’un site bancaire par ex). On peut atténuer en hébergeant le site sur un domaine Cloudflare (utiliser Cloudflare pour cacher l’IP du NAS et bénéficier de leur anti-DDoS par exemple). - Sandboxing Synology : DSM7 a renforcé certaines sécurités, par exemple l’accès root. Il faudra parfois bricoler pour installer des choses. On respectera autant que possible la manière propre (via paquets officiels ou Docker). - Espace : on en a déjà parlé, pas un souci majeur. Mais il faut vérifier la santé des disques etc., comme tout NAS (Synology envoie des alertes en cas de secteur défectueux, etc.).
10.5 Éthiques et légales
Bien que non explicitement demandé, à noter : - Droit d’utilisation des données : CoinGecko et autres fournissent des données libres, CoinMarketCap c’est discutable (dans le sens où CMC impose un usage non commercial sur le free). Notre site étant public et gratuit, on est normalement conformes (vérifier les T&C de chaque API). - RGPD : si on collecte des emails utilisateurs (données personnelles), on doit se conformer à la RGPD. Donc prévoir un moyen de suppression de compte sur demande, stocker le moins d’infos possible, mentionner dans une Politique de confidentialité l’utilisation des emails (ex: uniquement pour login et envoi éventuel d’alertes si opt-in). - Disclaimer : on l’a mentionné, mais légalement il faut prévenir que ce ne sont pas des conseils financiers et qu’on n’est pas responsables des décisions prises sur la base du score. Un texte de disclaimer sera affiché (pied de page ou pop-up avant usage) pour dégager la responsabilité en cas de pertes financières de l’utilisateur en suivant le score. Par exemple, “Les scores sont fournis à titre informatif, sans garantie, et ne constituent pas une recommandation d’investissement[22].”
10.6 Limites connues et améliorations futures
Pour terminer, on peut signaler quelques limites de la version initiale du projet et des pistes pour les dépasser : - Le score Sécurité est partiel (faute de données complètes sur audits, etc.) – on pourrait intégrer à l’avenir des sources comme Hacken, CertiK, ou récupérer un flux de news sur les hacks pour impacter le score. - Le projet se concentre sur l’aspect quantitatif ; il ne remplace pas une analyse fondamentale humaine. C’est un outil de screening. - La pondération personnalisée est puissante mais l’utilisateur lambda pourrait être dérouté – on envisagera peut-être des profils prédéfinis comme mentionné (boutons pour auto-régler les poids). - La base top 1000 + trending sera mise à jour : qui décide quelles cryptos sont suivies ? On supposera qu’une fois par mois on peut rafraîchir la liste top 1000 selon la cap, pour inclure les nouveaux entrants. On devra faire migrer l’historique de celles qui sortent (on peut garder l’historique même si elle sort du top1000, c’est pas grave). - Le trending hors top1000 : la composition de ces 100 trending change possiblement tous les jours beaucoup. On peut choisir de lister ces trending du jour sans historique complet pour eux (car un jour trending, le lendemain plus). Ou bien si un coin trending devient fréquent, l’ajouter au suivi permanent. C’est un détail de mise en œuvre : initialement, on peut se baser sur l’endpoint trending de CMC quotidien sans stocker un gros historique pour eux, juste les afficher.
En conclusion, cette spécification couvre l’ensemble du cycle de vie du projet, du recueil de données brutes à l’affichage utilisateur, en passant par les calculs, le stockage, la sécurité et la maintenabilité. L’équipe de développement pourra s’appuyer sur ce document pour implémenter chaque composant de manière cohérente et complète, en gardant à l’esprit les objectifs principaux : fiabilité des scores, performance de l’application, et clarté pour l’utilisateur final.
Sources : CoinMarketCap (trending definition)[1]; CoinMarketCap Academy (définition du RSI)[4]; BraveNewCoin (corrélation followers Twitter – valorisation)[3]; TwitterScore (importance de la communauté)[2]; DefiLlama (définition du TVL)[10]; CoinGecko/Reddit (API limits & attribution)[12][13][28]; Medium (déploiement Python sur Synology)[18][19]; CoinGecko API (scores développeur/communauté historiques)[6]; CoinCheckup disclaimer[22].
________________________________________
[1] [7] What Are The Trending Cryptocurrencies On CoinMarketCap? | CoinMarketCap
https://coinmarketcap.com/trending-cryptocurrencies/
[2]  TwitterScore | Crypto and NFT Insights Based on Twitter Followers 
https://twitterscore.io/
[3] Crypto Value? Turns Out, It’s All About the Twitter Followers - Brave New Coin
https://bravenewcoin.com/insights/crypto-value-turns-out-its-all-about-the-twitter-followers
[4] Relative Strength Index (RSI) Definition | CoinMarketCap
https://coinmarketcap.com/academy/glossary/relative-strength-index-rsi
[5] Tokenomics: 5 Critical Crypto Valuation Factors - Alpaca Markets
https://alpaca.markets/content/tokenomics-guide
[6] coingecko package - github.com/kkyr/coingecko-api/coingecko
https://pkg.go.dev/github.com/kkyr/coingecko-api/coingecko
[8] [9] [13] 5 bests cryptocurrency price APIs for developers | by Théo Voglimacci | Medium
https://theovogg.medium.com/5-bests-cryptocurrency-price-apis-for-developers-505a3be623b5
[10] [17] Frequently Asked Questions | DefiLlama
https://docs.llama.fi/faqs/frequently-asked-questions
[11] I can't access Mariadb 10 with Python. - Synology Community
https://community.synology.com/enu/forum/1/post/188394
[12] Real API limits? : r/coingecko
https://www.reddit.com/r/coingecko/comments/16bc259/real_api_limits/
[14] What is CoinGecko Rank and CoinGecko Score?
https://support.coingecko.com/hc/en-us/articles/17982928280601-What-is-CoinGecko-Rank-and-CoinGecko-Score
[15] CoinMarketCap API Pricing Plans
https://coinmarketcap.com/api/pricing/
[16] API Docs - DefiLlama
https://api-docs.defillama.com/
[18] [19] [20] [21] [23] [24] [25] [26] [27] Deploying Python Flask in Synology DSM 7 using uWSGI | by Muhammad Rizqi Nur | Medium
https://medium.com/@rizqinur2010/deploying-python-flask-in-synology-dsm-7-without-docker-d99f1603bc87
[22] Cryptocurrency Prices, Charts & Crypto Market Cap - CoinCheckup
https://coincheckup.com/how-we-stay-unbiased
[28] CoinGecko API: The Cryptocurrency Data Powerhouse - Zuplo
https://zuplo.com/learning-center/coingecko-api


## Running the API

```bash
uvicorn backend.app.main:app --reload
```

## Using the front-end

Open `frontend/index.html` in a browser once the API is running. It will fetch and
display the list of cryptocurrencies with their price and global score.

## Déploiement sur un NAS Synology avec Container Manager

1. Installez le paquet **Container Manager** depuis le Centre de paquets Synology.
2. (Facultatif) Activez l'accès SSH dans **Panneau de configuration → Terminal & SNMP** si vous souhaitez utiliser la ligne de commande.
3. Clonez ce dépôt ou copiez le fichier `docker-compose.yml` sur votre NAS :
   ```bash
   git clone https://github.com/<votre-utilisateur>/Tokenlysis.git
   cd Tokenlysis
   ```
4. Ouvrez **Container Manager → Projet → Créer → Importer** et sélectionnez le fichier `docker-compose.yml` du dépôt.
5. Dans le projet nouvellement créé, cliquez sur **Construire** puis **Démarrer** pour lancer le conteneur.
   Vous pouvez également exécuter la commande suivante via SSH :
   ```bash
   docker compose up -d
   ```
6. Depuis un navigateur du réseau local, accédez à `http://<ip_du_nas>:8000` (la documentation de l'API est disponible sur `/docs`).

### Tâche planifiée DSM

Pour redémarrer automatiquement le service (par exemple au démarrage du NAS) :

1. Ouvrez **Panneau de configuration → Planificateur de tâches**.
2. Cliquez sur **Créer → Tâche planifiée → Script défini par l'utilisateur**.
3. Donnez un nom (par ex. "Tokenlysis") et choisissez l'utilisateur `root`.
4. Dans l'onglet **Planification**, sélectionnez "Au démarrage" ou la
   fréquence désirée.
5. Dans l'onglet **Paramètres de tâche**, indiquez le script :
   ```bash
   cd /chemin/vers/Tokenlysis
   docker compose up -d
   ```
6. Validez. Le conteneur sera lancé automatiquement selon la planification.

